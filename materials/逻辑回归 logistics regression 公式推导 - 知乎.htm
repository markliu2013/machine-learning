<!DOCTYPE html>
<!-- saved from url=(0037)https://zhuanlan.zhihu.com/p/44591359 -->
<html lang="zh" data-hairline="true" data-theme="light" data-focus-visible=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><title>逻辑回归 logistics regression 公式推导 - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="renderer" content="webkit"><meta name="force-rendering" content="webkit"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"><meta data-react-helmet="true" name="description" content="原创，转载请注明出处。（常规字母代表标量，粗体字母代表向量，大写粗体字母代表矩阵） 逻辑回归虽然名字里面有回归，但是主要用来解决分类问题。 一、线性回归（Linear Regression）线性回归的表达式：f(\bm{x})…"><meta data-react-helmet="true" property="og:title" content="逻辑回归 logistics regression 公式推导"><meta data-react-helmet="true" property="og:url" content="https://zhuanlan.zhihu.com/p/44591359"><meta data-react-helmet="true" property="og:description" content="原创，转载请注明出处。（常规字母代表标量，粗体字母代表向量，大写粗体字母代表矩阵） 逻辑回归虽然名字里面有回归，但是主要用来解决分类问题。 一、线性回归（Linear Regression）线性回归的表达式：f(\bm{x})…"><meta data-react-helmet="true" property="og:image" content="https://pic2.zhimg.com/v2-c7d295979e8d98ade8a93ae34ddc6320_b.jpg"><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" property="og:site_name" content="知乎专栏"><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png"><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png" sizes="152x152"><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.b3e6278d.png" sizes="120x120"><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.7a750095.png" sizes="76x76"><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.a4a761d4.png" sizes="60x60"><link rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/static/favicon.ico"><link rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/static/search.xml" title="知乎"><link rel="dns-prefetch" href="https://static.zhimg.com/"><link rel="dns-prefetch" href="https://pic1.zhimg.com/"><link rel="dns-prefetch" href="https://pic2.zhimg.com/"><link rel="dns-prefetch" href="https://pic3.zhimg.com/"><link rel="dns-prefetch" href="https://pic4.zhimg.com/"><style>
.u-safeAreaInset-top {
  height: constant(safe-area-inset-top) !important;
  height: env(safe-area-inset-top) !important;
  
}
.u-safeAreaInset-bottom {
  height: constant(safe-area-inset-bottom) !important;
  height: env(safe-area-inset-bottom) !important;
  
}
</style><link href="./逻辑回归 logistics regression 公式推导 - 知乎_files/app.006eaa63459e0c5fdfda.css" rel="stylesheet"><link rel="stylesheet"><script defer="" crossorigin="anonymous" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/init.js" data-sentry-config="{&quot;dsn&quot;:&quot;https://65e244586890460588f00f2987137aa8@crash2.zhihu.com/193&quot;,&quot;sampleRate&quot;:0.1,&quot;release&quot;:&quot;2198-aa9f8351&quot;,&quot;ignoreErrorNames&quot;:[&quot;NetworkError&quot;,&quot;SecurityError&quot;],&quot;ignoreErrors&quot;:[&quot;origin message&quot;,&quot;Network request failed&quot;,&quot;Loading chunk&quot;,&quot;这个系统不支持该功能。&quot;,&quot;Can&#39;t find variable: webkit&quot;,&quot;Can&#39;t find variable: $&quot;,&quot;内存不足&quot;,&quot;out of memory&quot;,&quot;DOM Exception 18&quot;,&quot;The operation is insecure&quot;,&quot;[object Event]&quot;,&quot;[object FileError]&quot;,&quot;[object DOMError]&quot;,&quot;[object Object]&quot;,&quot;拒绝访问。&quot;,&quot;Maximum call stack size exceeded&quot;,&quot;UploadError&quot;,&quot;无法 fetch&quot;,&quot;draft-js&quot;,&quot;缺少 JavaScript 对象&quot;,&quot;componentWillEnter&quot;,&quot;componentWillLeave&quot;,&quot;componentWillAppear&quot;,&quot;getInlineStyleAt&quot;,&quot;getCharacterList&quot;],&quot;whitelistUrls&quot;:[&quot;static.zhihu.com&quot;]}"></script><link rel="stylesheet" type="text/css" href="./逻辑回归 logistics regression 公式推导 - 知乎_files/modals.6819be204d1e8ad13ab0.css"><script charset="utf-8" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/column.modals.2cdb63ca58235ddc3ce6.js"></script><link rel="stylesheet" type="text/css" href="./逻辑回归 logistics regression 公式推导 - 知乎_files/richinput.aaf6d724da7e7bd2d1f4.css"><script charset="utf-8" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/column.richinput.c430209d8486f20a67e0.js"></script></head><body class="WhiteBg-body Body--isAppleDevice"><div id="root"><div class="App" data-reactroot=""><div class="LoadingBar"></div><main role="main" class="App-main"><div class="Post-content" data-zop-usertoken="{&quot;userToken&quot;:&quot;moochliu2016&quot;}" data-zop="{&quot;authorName&quot;:&quot;折射&quot;,&quot;itemId&quot;:44591359,&quot;title&quot;:&quot;逻辑回归 logistics regression 公式推导&quot;,&quot;type&quot;:&quot;article&quot;}" data-za-detail-view-path-module="PostItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Post&quot;,&quot;token&quot;:&quot;44591359&quot;}}}"><div class="ColumnPageHeader-Wrapper"><div><div class="Sticky ColumnPageHeader" style=""><div class="ColumnPageHeader-content"><a href="https://www.zhihu.com/" aria-label="知乎"><svg viewBox="0 0 200 91" class="Icon ZhihuLogo ZhihuLogo--blue Icon--logo" style="height:30px;width:64px" width="64" height="30" aria-hidden="true"><title></title><g><path d="M53.29 80.035l7.32.002 2.41 8.24 13.128-8.24h15.477v-67.98H53.29v67.978zm7.79-60.598h22.756v53.22h-8.73l-8.718 5.473-1.587-5.46-3.72-.012v-53.22zM46.818 43.162h-16.35c.545-8.467.687-16.12.687-22.955h15.987s.615-7.05-2.68-6.97H16.807c1.09-4.1 2.46-8.332 4.1-12.708 0 0-7.523 0-10.085 6.74-1.06 2.78-4.128 13.48-9.592 24.41 1.84-.2 7.927-.37 11.512-6.94.66-1.84.785-2.08 1.605-4.54h9.02c0 3.28-.374 20.9-.526 22.95H6.51c-3.67 0-4.863 7.38-4.863 7.38H22.14C20.765 66.11 13.385 79.24 0 89.62c6.403 1.828 12.784-.29 15.937-3.094 0 0 7.182-6.53 11.12-21.64L43.92 85.18s2.473-8.402-.388-12.496c-2.37-2.788-8.768-10.33-11.496-13.064l-4.57 3.627c1.363-4.368 2.183-8.61 2.46-12.71H49.19s-.027-7.38-2.372-7.38zm128.752-.502c6.51-8.013 14.054-18.302 14.054-18.302s-5.827-4.625-8.556-1.27c-1.874 2.548-11.51 15.063-11.51 15.063l6.012 4.51zm-46.903-18.462c-2.814-2.577-8.096.667-8.096.667s12.35 17.2 12.85 17.953l6.08-4.29s-8.02-11.752-10.83-14.33zM199.99 46.5c-6.18 0-40.908.292-40.953.292v-31.56c1.503 0 3.882-.124 7.14-.376 12.773-.753 21.914-1.25 27.427-1.504 0 0 3.817-8.496-.185-10.45-.96-.37-7.24 1.43-7.24 1.43s-51.63 5.153-72.61 5.64c.5 2.756 2.38 5.336 4.93 6.11 4.16 1.087 7.09.53 15.36.277 7.76-.5 13.65-.76 17.66-.76v31.19h-41.71s.88 6.97 7.97 7.14h33.73v22.16c0 4.364-3.498 6.87-7.65 6.6-4.4.034-8.15-.36-13.027-.566.623 1.24 1.977 4.496 6.035 6.824 3.087 1.502 5.054 2.053 8.13 2.053 9.237 0 14.27-5.4 14.027-14.16V53.93h38.235c3.026 0 2.72-7.432 2.72-7.432z" fill-rule="evenodd"></path></g></svg></a><i class="ColumnPageHeader-Line"></i><div class="ColumnPageHeader-Title"><a class="ColumnLink ColumnPageHeader-Link" href="https://zhuanlan.zhihu.com/qinlibo-ml"><img class="Avatar Avatar--round" width="30" height="30" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-dade4f3465c87462e77ba24a253c0e20_is.jpg" srcset="https://pic1.zhimg.com/v2-dade4f3465c87462e77ba24a253c0e20_im.jpg 2x" alt="机器学习算法与自然语言处理"></a><div class="ColumnPageHeader-TitleName"><span class="ColumnPageHeader-TitleMeta">首发于</span><a class="ColumnLink ColumnPageHeader-TitleColumn" href="https://zhuanlan.zhihu.com/qinlibo-ml">机器学习算法与自然语言处理</a></div></div><div class="ColumnPageHeader-Button"><button type="button" class="Button FollowButton ColumnPageHeader-FollowButton Button--primary Button--grey">已关注</button><button type="button" class="Button ColumnPageHeader-WriteButton Button--blue"><svg class="Zi Zi--EditSurround" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M18.453 7.992l-1.833-1.65.964-.978a1.223 1.223 0 0 1 1.73-.012l.005.006a1.24 1.24 0 0 1 .007 1.748l-.873.886zm-1.178 1.194l-5.578 5.66-1.935.697a.393.393 0 0 1-.504-.504l.697-1.935 5.488-5.567 1.832 1.65zM7.58 5.848l5.654.006-1.539 1.991-3.666.012A1.02 1.02 0 0 0 7 8.868v7.993c0 .558.46 1.01 1.029 1.01l7.941-.01c.568 0 1.03-.453 1.03-1.012v-4.061l2-1.442v6.002c0 1.397-1.2 2.501-2.62 2.501H7.574C6.153 19.85 5 18.717 5 17.32V8.35c0-1.397 1.16-2.502 2.58-2.502z"></path></svg>写文章</button><div class="Popover"><button title="更多" type="button" id="Popover2-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover2-content" class="Button ColumnPageHeader-MenuToggler Button--plain"><svg class="Zi Zi--Dots" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M5 14a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div></div><img class="TitleImage" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-c7d295979e8d98ade8a93ae34ddc6320_1200x500.jpg" alt="逻辑回归 logistics regression 公式推导"><article class="Post-Main Post-NormalMain" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">逻辑回归 logistics regression 公式推导</h1><div class="Post-Author"><div class="AuthorInfo" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="name" content="折射"><meta itemprop="image" content="https://pic1.zhimg.com/83355acd2_l.jpg"><meta itemprop="url" content="https://www.zhihu.com/people/deng-gao-shan"><meta itemprop="zhihu:followerCount"><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="Popover3-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover3-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/deng-gao-shan"><img class="Avatar Avatar--round AuthorInfo-avatar" width="38" height="38" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/83355acd2_xs.jpg" srcset="https://pic1.zhimg.com/83355acd2_l.jpg 2x" alt="折射"></a></div></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><div class="Popover"><div id="Popover4-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover4-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/deng-gao-shan">折射</a></div></div><a class="UserLink-badge" data-tooltip="已认证的个人" href="https://www.zhihu.com/question/48510028" target="_blank" rel="noopener noreferrer"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--BadgeCert" fill="currentColor" viewBox="0 0 24 24" width="18" height="18"><g fill="none" fill-rule="evenodd"><path fill="#0F88EB" d="M2.64 13.39c1.068.895 1.808 2.733 1.66 4.113l.022-.196c-.147 1.384.856 2.4 2.24 2.278l-.198.016c1.387-.122 3.21.655 4.083 1.734l-.125-.154c.876 1.084 2.304 1.092 3.195.027l-.127.152c.895-1.068 2.733-1.808 4.113-1.66l-.198-.022c1.386.147 2.402-.856 2.279-2.238l.017.197c-.122-1.388.655-3.212 1.734-4.084l-.154.125c1.083-.876 1.092-2.304.027-3.195l.152.127c-1.068-.895-1.808-2.732-1.66-4.113l-.022.198c.147-1.386-.856-2.4-2.24-2.279l.198-.017c-1.387.123-3.21-.654-4.083-1.733l.125.153c-.876-1.083-2.304-1.092-3.195-.027l.127-.152c-.895 1.068-2.733 1.808-4.113 1.662l.198.02c-1.386-.147-2.4.857-2.279 2.24L4.4 6.363c.122 1.387-.655 3.21-1.734 4.084l.154-.126c-1.083.878-1.092 2.304-.027 3.195l-.152-.127z"></path><path fill="#FFF" d="M9.78 15.728l-2.633-2.999s-.458-.705.242-1.362c.7-.657 1.328-.219 1.328-.219l1.953 2.132 4.696-4.931s.663-.348 1.299.198c.636.545.27 1.382.27 1.382s-3.466 3.858-5.376 5.782c-.98.93-1.778.017-1.778.017z"></path></g></svg></span></a></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="AuthorInfo-badgeText">南加州大学 计算机科学硕士在读</div></div></div></div></div><button type="button" class="Button FollowButton Button--primary Button--blue"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Plus FollowButton-icon" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M13.491 10.488s-.012-5.387 0-5.998c-.037-1.987-3.035-1.987-2.997 0-.038 1.912 0 5.998 0 5.998H4.499c-1.999.01-1.999 3.009 0 3.009s5.995-.01 5.995-.01v5.999c0 2.019 3.006 2.019 2.997 0-.01-2.019 0-5.998 0-5.998s3.996.009 6.004.009c2.008 0 2.008-3-.01-3.009h-5.994z" fill-rule="evenodd"></path></svg></span>关注他</button></div><div><span class="Voters"><button type="button" class="Button Button--plain">291 人<!-- -->赞同了该文章</button></span></div></header><div class="Post-RichTextContainer"><div class="RichText ztext Post-RichText" ecommerce="[object Object]"><p>原创，转载请注明出处。</p><p>（常规字母代表标量，粗体字母代表向量，大写粗体字母代表矩阵）</p><p class="ztext-empty-paragraph"><br></p><p>逻辑回归虽然名字里面有回归，但是主要用来解决分类问题。</p><p class="ztext-empty-paragraph"><br></p><p><b>一、线性回归（Linear Regression）</b></p><p>线性回归的表达式：</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation" alt="[公式]" eeimg="1" data-formula="f(\bm{x}) = \bm{w}^T\bm{x} + b"></p><p>线性回归对于给定的输入 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(1)" alt="[公式]" eeimg="1" data-formula="\bm{x}"> ，输出的是一个数值 y ，因此它是一个解决回归问题的模型。</p><p>为了消除掉后面的常数项b，我们可以令 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(2)" alt="[公式]" eeimg="1" data-formula="\begin{matrix} \bm{x}^{&#39;} &amp;= [ 1 &amp; \bm{x}]^T  \end{matrix}"> ，同时 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(3)" alt="[公式]" eeimg="1" data-formula="\begin{matrix} \bm{w}^{&#39;} &amp;= [ b &amp; \bm{w}]^T \end{matrix}"> ，也就是说给x多加一项而且值恒为1，这样b就到了w里面去了，直线方程可以化简成为：</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(4)" alt="[公式]" eeimg="1" data-formula="f(\bm{x&#39;}) = \bm{w&#39;}^T\bm{x&#39;} "> </p><p>在接下来的文章中为了方便，我们所使用的 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(5)" alt="[公式]" eeimg="1" data-formula="\bm{w},\bm{x}"> 其实指代的是 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(6)" alt="[公式]" eeimg="1" data-formula="w&#39;,x&#39;"> 。</p><p class="ztext-empty-paragraph"><br></p><p><b>二、分类问题（Classification）</b></p><p>二分类问题就是给定的输入 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(1)" alt="[公式]" eeimg="1" data-formula="\bm{x}">，判断它的标签是A类还是类。二分类问题是最简单的分类问题。我们可以把多分类问题转化成一组二分类问题。比如最简单的是OVA(One-vs-all)方法，比如一个10分类问题，我们可以分别判断输入 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(1)" alt="[公式]" eeimg="1" data-formula="\bm{x}"> 是否属于某个类，从而转换成10个二分类问题。</p><p>因此，解决了二分类问题，相当于解决了多分类问题。</p><p class="ztext-empty-paragraph"><br></p><p><b>三、如何用连续的数值去预测离散的标签值呢？</b></p><p>线性回归的输出是一个数值，而不是一个标签，显然不能直接解决二分类问题。那我如何改进我们的回归模型来预测标签呢？</p><p>一个最直观的办法就是设定一个阈值，比如0，如果我们预测的数值 y &gt; 0 ，那么属于标签A，反之属于标签B，采用这种方法的模型又叫做<b>感知机</b>（Perceptron）。</p><p>另一种方法，我们不去直接预测标签，而是去预测标签为A概率，我们知道概率是一个[0,1]区间的连续数值，那我们的输出的数值就是标签为A的概率。一般的如果标签为A的概率大于0.5，我们就认为它是A类，否则就是B类。这就是我们的这次的主角<b>逻辑回归模型 </b>(Logistics Regression)。</p><p class="ztext-empty-paragraph"><br></p><p><b>四、逻辑回归（logistics regression）</b></p><p>明确了预测目标是标签为A的概率。</p><p>我们知道，概率是属于[0,1]区间。但是线性模型 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(7)" alt="[公式]" eeimg="1" data-formula="f(\bm{x}) = \bm{w}^T\bm{x}"> 值域是 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(8)" alt="[公式]" eeimg="1" data-formula="(-\infty,\infty)"> 。</p><p>我们不能直接基于线性模型建模。需要找到一个模型的值域刚好在[0,1]区间，同时要足够好用。</p><p>于是，选择了我们的sigmoid函数。</p><p>它的表达式为： <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(9)" alt="[公式]" eeimg="1" data-formula="\sigma(x) =\frac{1}{1+e^{-x}}"> 。</p><p>它的图像：</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-ab82d755dba95f0585678fe2d4af28d6_b.jpg" data-size="normal" data-rawwidth="468" data-rawheight="167" class="origin_image zh-lightbox-thumb" width="468" data-original="https://pic3.zhimg.com/v2-ab82d755dba95f0585678fe2d4af28d6_r.jpg"/></noscript><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-ab82d755dba95f0585678fe2d4af28d6_hd.jpg" data-size="normal" data-rawwidth="468" data-rawheight="167" class="origin_image zh-lightbox-thumb lazy" width="468" data-original="https://pic3.zhimg.com/v2-ab82d755dba95f0585678fe2d4af28d6_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-ab82d755dba95f0585678fe2d4af28d6_b.jpg"><figcaption>sigmoid函数</figcaption></figure><p>这个函数的有很多非常好的性质，一会儿你就会感受到。但是我们不能直接拿了sigmoid函数就用，毕竟它连要训练的参数 w 都没得。</p><p>我们结合sigmoid函数，线性回归函数，把线性回归模型的输出作为sigmoid函数的输入。于是最后就变成了逻辑回归模型：</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(10)" alt="[公式]" eeimg="1" data-formula="y=\sigma(f(\bm{x})) = \sigma(\bm{w}^T\bm{x})=\frac{1}{1+e^{-\bm{w}^T\bm{x}}}"> </p><p>假设我们已经训练好了一组权值 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(11)" alt="[公式]" eeimg="1" data-formula="\bm{w}^T"> 。只要把我们需要预测的 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(1)" alt="[公式]" eeimg="1" data-formula="\bm{x}"> 代入到上面的方程，输出的y值就是这个标签为A的概率，我们就能够判断输入数据是属于哪个类别。</p><p>接下来就来详细介绍，如何利用一组采集到的真实样本，训练出参数w的值。</p><p class="ztext-empty-paragraph"><br></p><p><b>五、逻辑回归的损失函数（Loss Function）</b></p><p>损失函数就是用来衡量模型的输出与真实输出的差别。</p><p>假设只有两个标签1和0， <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(12)" alt="[公式]" eeimg="1" data-formula="y_n \in\{0, 1\}"> 。我们把采集到的任何一组样本看做一个事件的话，那么这个事件发生的概率假设为p。我们的模型y的值等于标签为1的概率也就是p。</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(13)" alt="[公式]" eeimg="1" data-formula="P_{y=1}=\frac{1}{1+e^{-\bm{w}^T\bm{x}}} = p"> </p><p>因为标签不是1就是0，因此标签为0的概率就是： <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(14)" alt="[公式]" eeimg="1" data-formula="P_{y=0} = 1-p"> 。</p><p>我们把单个样本看做一个事件，那么这个事件发生的概率就是：</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(15)" alt="[公式]" eeimg="1" data-formula="P(y|\bm{x})=\left\{ \begin{aligned} p, y=1 \\ 1-p,y=0 \end{aligned} \right."> </p><p>这个函数不方便计算，它等价于:</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(16)" alt="[公式]" eeimg="1" data-formula="P(y_i|\bm{x}_i) = p^{y_i}(1-p)^{1-{y_i}}"> 。</p><p>解释下这个函数的含义，我们采集到了一个样本 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(17)" alt="[公式]" eeimg="1" data-formula="(\bm{x_i},y_i)"> 。对这个样本，它的标签是 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(18)" alt="[公式]" eeimg="1" data-formula="y_i"> 的概率是 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(19)" alt="[公式]" eeimg="1" data-formula="p^{y_i}(1-p)^{1-{y_i}}"> 。 （当y=1，结果是p；当y=0，结果是1-p）。</p><p>如果我们采集到了一组数据一共N个， <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(20)" alt="[公式]" eeimg="1" data-formula="\{(\bm{x}_1,y_1),(\bm{x}_2,y_2),(\bm{x}_3,y_3)...(\bm{x}_N,y_N)\}"> ，这个合成在一起的合事件发生的总概率怎么求呢？其实就是将每一个样本发生的概率相乘就可以了，即采集到这组样本的概率：</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(21)" alt="[公式]" eeimg="1" data-formula="\begin{aligned} P_{总} &amp;= P(y_1|\bm{x}_1)P(y_2|\bm{x}_2)P(y_3|\bm{x}_3)....P(y_N|\bm{x}_N) \\  &amp;= \prod_{n=1}^{N}p^{y_n}(1-p)^{1-y_n}  \end{aligned}"> </p><p>注意<img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(22)" alt="[公式]" eeimg="1" data-formula="P_{总 }"> 是一个函数，并且未知的量只有 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(23)" alt="[公式]" eeimg="1" data-formula="\bm{w}"> （在p里面）。</p><p>由于连乘很复杂，我们通过两边取对数来把连乘变成连加的形式，即：</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(24)" alt="[公式]" eeimg="1" data-formula="\begin{aligned} F(\bm{w})=ln(P_{总} )  &amp;= ln(\prod_{n=1}^{N}p^{y_n}(1-p)^{1-y_n} ) \\ &amp;= \sum_{n=1}^{N}ln (p^{y_n}(1-p)^{1-y_n}) \\ &amp;= \sum_{n=1}^{N}(y_n ln (p) + (1-y_n)ln(1-p)) \end{aligned} "> </p><p>其中， <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(25)" alt="[公式]" eeimg="1" data-formula="p = \frac{1}{1+e^{-\bm{w}^T\bm{x}}} "> </p><p>这个函数 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(26)" alt="[公式]" eeimg="1" data-formula="F(\bm{w})">  又叫做它的<b>损失函数</b>。损失函数可以理解成衡量我们当前的模型的输出结果，跟实际的输出结果之间的差距的一种函数。这里的损失函数的值等于事件发生的总概率，我们希望它越大越好。但是跟损失的含义有点儿违背，因此也可以在前面取个负号。</p><p class="ztext-empty-paragraph"><br></p><p><b>六、最大似然估计MLE(Maximum Likelihood Estimation)</b></p><p>我们在真实世界中并不能直接看到概率是多少，我们只能观测到事件是否发生。也就是说，我们只能知道一个样本它实际的标签是1还是0。那么我们如何估计参数 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(23)" alt="[公式]" eeimg="1" data-formula="\bm{w}"> 跟b的值呢？</p><p>最大似然估计MLE(Maximum Likelihood Estimation)，就是一种估计参数 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(23)" alt="[公式]" eeimg="1" data-formula="\bm{w}"> 的方法。在这里如何使用MLE来估计 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(23)" alt="[公式]" eeimg="1" data-formula="\bm{w}"> 呢？</p><p>在上一节，我们知道损失函数 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(27)" alt="[公式]" eeimg="1" data-formula="F（\bm{w}）"> 是正比于总概率 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(28)" alt="[公式]" eeimg="1" data-formula="P_{总}"> 的，而 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(27)" alt="[公式]" eeimg="1" data-formula="F（\bm{w}）"> 又只有一个变量 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(23)" alt="[公式]" eeimg="1" data-formula="\bm{w}"> 。也就是说，通过改变 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(23)" alt="[公式]" eeimg="1" data-formula="\bm{w}"> 的值，就能得到不同的总概率值 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(28)" alt="[公式]" eeimg="1" data-formula="P_{总}"> 。那么当我们选取的某个 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(29)" alt="[公式]" eeimg="1" data-formula="\bm{w}^*"> 刚好使得总概率 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(28)" alt="[公式]" eeimg="1" data-formula="P_{总}"> 取得最大值的时候。我们就认为这个 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(29)" alt="[公式]" eeimg="1" data-formula="\bm{w}^*"> 就是我们要求得的 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(23)" alt="[公式]" eeimg="1" data-formula="\bm{w}"> 的值，这就是最大似然估计的思想。</p><p>现在我们的问题变成了，找到一个 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(29)" alt="[公式]" eeimg="1" data-formula="\bm{w}^*"> ，使得我们的总事件发生的概率，即损失函数 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(27)" alt="[公式]" eeimg="1" data-formula="F（\bm{w}）"> 取得最大值，这句话用数学语言表达就是：</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(30)" alt="[公式]" eeimg="1" data-formula="\bm{w^*} = arg\max_{w}F(\bm{w}) = -arg\min_{w}F(\bm{w}) "> </p><p class="ztext-empty-paragraph"><br></p><p><b>七、 求</b><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(27)" alt="[公式]" eeimg="1" data-formula="F（\bm{w}）"><b> 的梯度</b> <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(31)" alt="[公式]" eeimg="1" data-formula="\nabla F（\bm{w}）"> </p><p><b>梯度的定义</b> </p><p>我们知道对于一个一维的标量x，它有导数 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(32)" alt="[公式]" eeimg="1" data-formula="x&#39;"> 。</p><p>对一个多维的向量 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(33)" alt="[公式]" eeimg="1" data-formula="\bm{x} = (x_1,x_2,x_3,..,x_n)">  来说，它的导数叫做梯度，也就是分别对于它的每个分量求导数 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(34)" alt="[公式]" eeimg="1" data-formula="\bm{x}&#39; = (x_1&#39;,x_2&#39;,x_3&#39;,..,x_n&#39;)"> 。</p><p class="ztext-empty-paragraph"><br></p><p>接下来请拿出纸笔，一起动手来推导出 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(31)" alt="[公式]" eeimg="1" data-formula="\nabla F（\bm{w}）"> 的表达式。请尽量尝试自己动手推导出来，如果哪一步不会了再看我的推导。</p><p class="ztext-empty-paragraph"><br></p><p><b>七（二）、求梯度的推导过程</b></p><p>为了求出 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(27)" alt="[公式]" eeimg="1" data-formula="F（\bm{w}）">的梯度<img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(31)" alt="[公式]" eeimg="1" data-formula="\nabla F（\bm{w}）">，我们需要做一些准备工作。原谅我非常不喜欢看大串的数学公式，所以我尽可能用最简单的数学符号来描述。当然可能不够严谨，但是我觉得更容易看懂。</p><p class="ztext-empty-paragraph"><br></p><p>首先，我们需要知道向量是如何求导的。具体的推导过程以及原理请参见 <a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/mounty_fsc/article/details/51588794" class=" wrap external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043">矩阵求导</a></p><p>我们只要记住几个结论就行了：对于一个矩阵 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(35)" alt="[公式]" eeimg="1" data-formula="\bm{A}"> 乘以一个向量的方程 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(36)" alt="[公式]" eeimg="1" data-formula="\bm{A}\bm{x}"> ，对向量 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(23)" alt="[公式]" eeimg="1" data-formula="\bm{w}"> 求导的结果是 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(37)" alt="[公式]" eeimg="1" data-formula="\bm{A}^T"> 。在这里我们把函数 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(36)" alt="[公式]" eeimg="1" data-formula="\bm{A}\bm{x}"> 对 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(23)" alt="[公式]" eeimg="1" data-formula="\bm{w}"> 求梯度简单记作 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(38)" alt="[公式]" eeimg="1" data-formula="（\bm{A}\bm{x}）&#39;"> 。因此<img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(39)" alt="[公式]" eeimg="1" data-formula="（\bm{A}\bm{x}）&#39; = \bm{A}^T"> , 推论是 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(40)" alt="[公式]" eeimg="1" data-formula="（\bm{x}^T\bm{A}）&#39; = \bm{A}"> ，我们把 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(41)" alt="[公式]" eeimg="1" data-formula="\bm{x},\bm{w}^T"> 代入进去，可以知道 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(42)" alt="[公式]" eeimg="1" data-formula="(\bm{w}^T\bm{x})&#39; = \bm{x}"> 。</p><p class="ztext-empty-paragraph"><br></p><p>然后求 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(43)" alt="[公式]" eeimg="1" data-formula="1-p"> 的值：</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(44)" alt="[公式]" eeimg="1" data-formula="1-p=\frac{e^{-\bm{w}^T\bm{x}} }{ 1+e^{-\bm{w}^T\bm{x}} }"> </p><p>p是一个关于变量 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(23)" alt="[公式]" eeimg="1" data-formula="\bm{w}"> 的函数，我们对p求导，通过链式求导法则，慢慢展开可以得：</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(45)" alt="[公式]" eeimg="1" data-formula="\begin{aligned}  p&#39; = f&#39;(\bm{w})&amp;= (\frac{1}{1+e^{-\bm{w}^T\bm{x}}} )&#39; \\ &amp;= -\frac{1}{ (1+e^{-\bm{w}^T\bm{x}} )^2}   · ( 1+e^{-\bm{w}^T\bm{x}})&#39; \\ &amp;= -\frac{1}{ (1+e^{-\bm{w}^T\bm{x}} )^2}   · e^{-\bm{w}^T\bm{x}}  · (-\bm{w}^T\bm{x})&#39; \\ &amp;= -\frac{1}{ (1+e^{-\bm{w}^T\bm{x}} )^2}   · e^{-\bm{w}^T\bm{x}}  · (-\bm{x} ) \\ &amp;= \frac{e^{-\bm{w}^T\bm{x}} }{ (1+e^{-\bm{w}^T\bm{x}} )^2} ·   \bm{x} \\ &amp;=  \frac{1}{ 1+e^{-\bm{w}^T\bm{x}} }    · \frac{e^{-\bm{w}^T\bm{x}} }{ 1+e^{-\bm{w}^T\bm{x}} }  · \bm{x} \\ &amp;= p(1-p)\bm{x} \end{aligned}"> </p><p>上面都是我们做的准备工作，总之我们得记住： <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(46)" alt="[公式]" eeimg="1" data-formula="p&#39; = p(1-p)\bm{x}"> , 并且可以知道 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(47)" alt="[公式]" eeimg="1" data-formula="(1-p)&#39; = -p(1-p)\bm{x}"> 。</p><p class="ztext-empty-paragraph"><br></p><p>下面我们正式开始对 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(26)" alt="[公式]" eeimg="1" data-formula="F(\bm{w})"> 求导，求导的时候请始终记住，我们的变量只有 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(23)" alt="[公式]" eeimg="1" data-formula="\bm{w}"> ，其他的什么 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(48)" alt="[公式]" eeimg="1" data-formula="y_n,\bm{x}_n "> 都是已知的，可以看做常数。</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(49)" alt="[公式]" eeimg="1" data-formula="\begin{aligned} \nabla F（\bm{w}）&amp; = \nabla （ \sum_{n=1}^{N}(y_n ln (p) + (1-y_n)ln(1-p)) ）\\ &amp;= \sum ( y_n ln&#39;(p) + (1-y_n) ln&#39;(1-p)) \\ &amp;= \sum( (y_n \frac{1}{p}p&#39;)+(1-y_n)\frac{1}{1-p}(1-p)&#39;) \\ &amp;= \sum(y_n(1-p)\bm{x}_n - (1-y_n)p\bm{x}_n) \\ &amp;= \sum_{n=1}^{N}{(y_n-p)\bm{x}_n} \end{aligned}"> </p><p>终于，我们求出了梯度 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(31)" alt="[公式]" eeimg="1" data-formula="\nabla F（\bm{w}）"> 的表达式了，现在我们再来看看它长什么样子：</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(50)" alt="[公式]" eeimg="1" data-formula="\begin{aligned} \nabla F（\bm{w}）&amp;= \sum_{n=1}^{N}{(y_n-p)\bm{x}_n}  \end{aligned}"> </p><p>它是如此简洁优雅，这就是我们选取sigmoid函数的原因之一。当然我们也能够把p再展开，即：</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(51)" alt="[公式]" eeimg="1" data-formula="\begin{aligned} \nabla F（\bm{w}）&amp;=  \sum_{n=1}^{N}{(y_n- \frac{1}{1+e^{-\bm{w}^T\bm{x}_n}} )\bm{x}_n}   \end{aligned}"> </p><p class="ztext-empty-paragraph"><br></p><p><b>八、梯度下降法（GD）与随机梯度下降法（SGD）</b></p><p>现在我们已经解出了损失函数 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(52)" alt="[公式]" eeimg="1" data-formula=" F（\bm{w}）">在任意 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(23)" alt="[公式]" eeimg="1" data-formula="\bm{w}"> 处的梯度 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(31)" alt="[公式]" eeimg="1" data-formula="\nabla F（\bm{w}）">，可是我们怎么算出来 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(53)" alt="[公式]" eeimg="1" data-formula="\bm{w^*}"> 呢？ 回到之前的问题，我们现在要求损失函数取最大值时候的<img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(53)" alt="[公式]" eeimg="1" data-formula="\bm{w^*}">的值：</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(54)" alt="[公式]" eeimg="1" data-formula="\bm{w^*} = arg\max_{w}F(\bm{w}) "></p><p><b>梯度下降法(Gradient Descent)</b>，可以用来解决这个问题。核心思想就是先随便初始化一个 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(55)" alt="[公式]" eeimg="1" data-formula="\bm{w}_0"> ，然后给定一个步长 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(56)" alt="[公式]" eeimg="1" data-formula="\eta"> ，通过不断地修改 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(57)" alt="[公式]" eeimg="1" data-formula="\bm{w}_{t+1} ">  &lt;- <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(58)" alt="[公式]" eeimg="1" data-formula="   \bm{w}_{t}"> ，从而最后靠近到达取得最大值的点，即不断进行下面的迭代过程，直到达到指定次数，或者梯度等于0为止。</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(59)" alt="[公式]" eeimg="1" data-formula="\bm{w}_{t+1} = \bm{w}_t + \eta\nabla F（\bm{w}）"> </p><p><b>随机梯度下降法（Stochastic Gradient Descent）</b>，如果我们能够在每次更新过程中，加入一点点噪声扰动，可能会更加快速地逼近最优值。在SGD中，我们不直接使用 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(31)" alt="[公式]" eeimg="1" data-formula="\nabla F（\bm{w}）"> ，而是采用另一个输出为随机变量的替代函数 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(60)" alt="[公式]" eeimg="1" data-formula="G(\bm{w})"> :</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(61)" alt="[公式]" eeimg="1" data-formula="\bm{w}_{t+1} = \bm{w}_t + \eta  G(\bm{w})"> </p><p>当然，这个替代函数 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(60)" alt="[公式]" eeimg="1" data-formula="G(\bm{w})">需要满足它的期望值等于<img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(31)" alt="[公式]" eeimg="1" data-formula="\nabla F（\bm{w}）">，相当于这个函数围绕着 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(31)" alt="[公式]" eeimg="1" data-formula="\nabla F（\bm{w}）"> 的输出值随机波动。</p><p class="ztext-empty-paragraph"><br></p><p>在这里我先解释一个问题：<b>为什么可以用梯度下降法？</b></p><p>因为逻辑回归的损失函数L是一个连续的凸函数（conveniently convex）。这样的函数的特征是，它只会有一个全局最优的点，不存在局部最优。对于GD跟SGD最大的潜在问题就是它们可能会陷入局部最优。然而这个问题在逻辑回归里面就不存在了，因为它的损失函数的良好特性，导致它并不会有好几个局部最优。当我们的GD跟SGD收敛以后，我们得到的极值点一定就是全局最优的点，因此我们可以放心地用GD跟SGD来求解。</p><p class="ztext-empty-paragraph"><br></p><p>好了，那我们要怎么实现学习算法呢？其实很简单，注意我们GD求导每次都耿直地用到了所有的样本点，从1一直到N都参与梯度计算。</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(62)" alt="[公式]" eeimg="1" data-formula="\begin{aligned} \nabla F（\bm{w}）&amp;=  \sum_{n=1}^{N}{(y_n- \frac{1}{1+e^{-\bm{w}^T\bm{x}_n}} )\bm{x}_n} \end{aligned}"> </p><p>在SGD中，我们每次只要均匀地、随机选取其中一个样本 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(17)" alt="[公式]" eeimg="1" data-formula="(\bm{x_i},y_i)"> ,用它代表整体样本，即把它的值乘以N，就相当于获得了梯度的无偏估计值，即 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(63)" alt="[公式]" eeimg="1" data-formula="E(G(\bm{w})) = \nabla F(\bm{w})"> ，因此SGD的更新公式为：</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(64)" alt="[公式]" eeimg="1" data-formula="\bm{w}_{t+1} = \bm{w}_t + \eta  N  {(y_n- \frac{1}{1+e^{-\bm{w}^T\bm{x}_n}} )\bm{x}_n}"> </p><p>这样我们前面的求和就没有了，同时 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(65)" alt="[公式]" eeimg="1" data-formula="\eta  N"> 都是常数， <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(66)" alt="[公式]" eeimg="1" data-formula="N"> 的值刚好可以并入 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(67)" alt="[公式]" eeimg="1" data-formula="\eta ">  当中,因此SGD的迭代更新公式为：</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(68)" alt="[公式]" eeimg="1" data-formula="\bm{w}_{t+1} = \bm{w}_t + \eta   {(y_n- \frac{1}{1+e^{-\bm{w}^T\bm{x}_n}} )\bm{x}_n}"> </p><p>其中 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(17)" alt="[公式]" eeimg="1" data-formula="(\bm{x_i},y_i)"> 是对所有样本随机抽样的一个结果。</p><p class="ztext-empty-paragraph"><br></p><p><b>九、逻辑回归的可解释性</b></p><p>逻辑回归最大的特点就是<b>可解释性</b>很强。</p><p>在模型训练完成之后，我们获得了一组n维的权重向量 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(23)" alt="[公式]" eeimg="1" data-formula="\bm{w}"> 跟偏差 b。</p><p>对于权重向量 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(23)" alt="[公式]" eeimg="1" data-formula="\bm{w}">，它的每一个维度的值，代表了这个维度的特征对于最终分类结果的贡献大小。假如这个维度是正，说明这个特征对于结果是有正向的贡献，那么它的值越大，说明这个特征对于分类为正起到的作用越重要。</p><p>对于偏差b (Bias)，一定程度代表了正负两个类别的判定的容易程度。假如b是0，那么正负类别是均匀的。如果b大于0，说明它更容易被分为正类，反之亦然。</p><p>根据逻辑回归里的权重向量在每个特征上面的大小，就能够对于每个特征的重要程度有一个量化的清楚的认识，这就是为什么说逻辑回归模型有着很强的解释性的原因。</p><p><b>十、决策边界</b></p><p>补充评论里的一个问题，逻辑回归的决策边界是否是线性的，相当于问曲线：</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(69)" alt="[公式]" eeimg="1" data-formula="\frac{1}{1+e^{-\bm{w}^T\bm{x}}} = 0.5"> </p><p>是不是的线性的，我们可以稍微化简一下上面的曲线公式，得到：</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(70)" alt="[公式]" eeimg="1" data-formula="e^{-\bm{w}^T\bm{x}} = 1 = e^{0} \\ 即  -\bm{w}^T\bm{x} = 0"> </p><p>我们得到了一个等价的曲线，显然它是一个超平面（它在数据是二维的情况下是一条直线）。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-3f2227d606b29be9619566b88d1f1912_b.jpg" data-caption="" data-size="normal" data-rawwidth="1934" data-rawheight="1098" class="origin_image zh-lightbox-thumb" width="1934" data-original="https://pic3.zhimg.com/v2-3f2227d606b29be9619566b88d1f1912_r.jpg"/></noscript><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-3f2227d606b29be9619566b88d1f1912_hd.jpg" data-caption="" data-size="normal" data-rawwidth="1934" data-rawheight="1098" class="origin_image zh-lightbox-thumb lazy" width="1934" data-original="https://pic3.zhimg.com/v2-3f2227d606b29be9619566b88d1f1912_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-3f2227d606b29be9619566b88d1f1912_b.jpg"></figure><p><b>十一、总结</b></p><p>终于一切都搞清楚了，现在我们来理一理思路，首先逻辑回归模型长这样：</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(71)" alt="[公式]" eeimg="1" data-formula="y=\frac{1}{1+e^{-\bm{w}^T\bm{x}}}"> </p><p>其中我们不知道的量是 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(23)" alt="[公式]" eeimg="1" data-formula="\bm{w}"> ，假设我们已经训练好了一个 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(29)" alt="[公式]" eeimg="1" data-formula="\bm{w}^*"> , 我们用模型来判断 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(72)" alt="[公式]" eeimg="1" data-formula="\bm{x}_i"> 的标签呢？很简单，直接将<img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(72)" alt="[公式]" eeimg="1" data-formula="\bm{x}_i">代入y中，求出来的值就是<img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(72)" alt="[公式]" eeimg="1" data-formula="\bm{x}_i">的标签是1的概率，如果概率大于0.5，那么我们认为它就是1类，否则就是0类。</p><p>那怎么得到 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(29)" alt="[公式]" eeimg="1" data-formula="\bm{w}^*"> 呢？</p><p>如果采用随机梯度下降法的话，我们首先随机产生一个<img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(23)" alt="[公式]" eeimg="1" data-formula="\bm{w}">的初始值 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(55)" alt="[公式]" eeimg="1" data-formula="\bm{w}_0"> ,然后通过公式不断迭代从而求得<img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(29)" alt="[公式]" eeimg="1" data-formula="\bm{w}^*">的值：</p><p><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(68)" alt="[公式]" eeimg="1" data-formula="\bm{w}_{t+1} = \bm{w}_t + \eta   {(y_n- \frac{1}{1+e^{-\bm{w}^T\bm{x}_n}} )\bm{x}_n}"> </p><p>每次迭代都从所有样本中随机抽取一个 <img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/equation(17)" alt="[公式]" eeimg="1" data-formula="(\bm{x_i},y_i)"> 来代入上述方程。</p><hr><p>原创，转载请注明出处。</p><p>初学者，不可避免出现错误。如果有任何问题，欢迎大家指正，也欢迎大家一起来交流讨论。</p></div></div><div class="ContentItem-time">编辑于 2019-07-21</div><div class="Post-topicsAndReviewer"><div class="TopicList Post-Topics"><div class="Tag Topic" data-za-detail-view-path-module="TopicItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Topic&quot;,&quot;token&quot;:&quot;19559450&quot;}}}"><span class="Tag-content"><a class="TopicLink" href="https://www.zhihu.com/topic/19559450" target="_blank"><div class="Popover"><div id="Popover5-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover5-content">机器学习</div></div></a></span></div><div class="Tag Topic" data-za-detail-view-path-module="TopicItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Topic&quot;,&quot;token&quot;:&quot;20178024&quot;}}}"><span class="Tag-content"><a class="TopicLink" href="https://www.zhihu.com/topic/20178024" target="_blank"><div class="Popover"><div id="Popover6-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover6-content">逻辑回归</div></div></a></span></div><div class="Tag Topic" data-za-detail-view-path-module="TopicItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Topic&quot;,&quot;token&quot;:&quot;19650497&quot;}}}"><span class="Tag-content"><a class="TopicLink" href="https://www.zhihu.com/topic/19650497" target="_blank"><div class="Popover"><div id="Popover7-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover7-content">梯度下降</div></div></a></span></div></div></div><div><div class="Sticky RichContent-actions is-fixed is-bottom" style="width: 690px; bottom: 0px; left: 607.5px;"><div class="ContentItem-actions" data-za-detail-view-path-module="BottomBar" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Post&quot;,&quot;id&quot;:&quot;44591359&quot;}}}"><span><button aria-label="赞同 291" type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M2 18.242c0-.326.088-.532.237-.896l7.98-13.203C10.572 3.57 11.086 3 12 3c.915 0 1.429.571 1.784 1.143l7.98 13.203c.15.364.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H3.955c-1.08 0-1.955-.517-1.955-1.9z" fill-rule="evenodd"></path></svg></span>赞同 291</button><button aria-label="反对" type="button" class="Button VoteButton VoteButton--down"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleDown" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M20.044 3H3.956C2.876 3 2 3.517 2 4.9c0 .326.087.533.236.896L10.216 19c.355.571.87 1.143 1.784 1.143s1.429-.572 1.784-1.143l7.98-13.204c.149-.363.236-.57.236-.896 0-1.386-.876-1.9-1.956-1.9z" fill-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Comment Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M10.241 19.313a.97.97 0 0 0-.77.2 7.908 7.908 0 0 1-3.772 1.482.409.409 0 0 1-.38-.637 5.825 5.825 0 0 0 1.11-2.237.605.605 0 0 0-.227-.59A7.935 7.935 0 0 1 3 11.25C3 6.7 7.03 3 12 3s9 3.7 9 8.25-4.373 9.108-10.759 8.063z" fill-rule="evenodd"></path></svg></span>47 条评论</button><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="Popover8-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover8-content"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Share Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2.931 7.89c-1.067.24-1.275 1.669-.318 2.207l5.277 2.908 8.168-4.776c.25-.127.477.198.273.39L9.05 14.66l.927 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.242c.584-.892-.212-2.029-1.234-1.796L2.93 7.89z" fill-rule="evenodd"></path></svg></span>分享</button></div></div><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Star Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5.515 19.64l.918-5.355-3.89-3.792c-.926-.902-.639-1.784.64-1.97L8.56 7.74l2.404-4.871c.572-1.16 1.5-1.16 2.072 0L15.44 7.74l5.377.782c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.219 1.274-.532 1.82-1.676 1.218L12 18.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z" fill-rule="evenodd"></path></svg></span>收藏</button><div class="Post-ActionMenuButton"><div class="Popover"><div id="Popover9-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover9-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Dots Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5 14a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4z" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></div><div class="Sticky--holder" style="position: static; top: auto; right: auto; bottom: 0px; left: 0px; display: block; float: none; margin: 0px 0px 10px; height: 54px;"></div></div></article><div class="Post-Sub Post-NormalSub"><div class="PostIndex-Contributions" data-za-detail-view-path-module="ColumnList" data-za-detail-view-path-module_name="文章被以下专栏收录" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:null}}"><h3 class="BlockTitle">文章被以下专栏收录</h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="https://zhuanlan.zhihu.com/qinlibo-ml"><div class="Popover"><div id="Popover10-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover10-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-dade4f3465c87462e77ba24a253c0e20_xs.jpg" srcset="https://pic1.zhimg.com/v2-dade4f3465c87462e77ba24a253c0e20_l.jpg 2x" alt="机器学习算法与自然语言处理"></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><a class="ColumnLink ColumnItem-Title" href="https://zhuanlan.zhihu.com/qinlibo-ml"><div class="Popover"><div id="Popover11-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover11-content">机器学习算法与自然语言处理</div></div></a></h2><div class="ContentItem-meta">公众号[自然语言处理与机器学习] 微信号yizhennotes</div></div><div class="ContentItem-extra"><button type="button" class="Button FollowButton Button--primary Button--grey">已关注</button></div></div></div><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="https://zhuanlan.zhihu.com/MLstudy"><div class="Popover"><div id="Popover12-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover12-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-a64760163f85c6deb6dc46852d82d8f0_xs.jpg" srcset="https://pic3.zhimg.com/v2-a64760163f85c6deb6dc46852d82d8f0_l.jpg 2x" alt="从零开始:一起入门机器学习"></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><a class="ColumnLink ColumnItem-Title" href="https://zhuanlan.zhihu.com/MLstudy"><div class="Popover"><div id="Popover13-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover13-content">从零开始:一起入门机器学习</div></div></a></h2><div class="ContentItem-meta">这是一个初学者的专栏，我们和初学者一起入门机器学习。在这里，我们不采用快速推进的模式。从最基本的数学基础到最前沿的应用，一步一个脚印，让扎实的读者拥有成为机器学习专家的潜力。</div></div><div class="ContentItem-extra"><button type="button" class="Button FollowButton Button--primary Button--grey">已关注</button></div></div></div></ul></div><div class="Recommendations-Main" style="width: 1905px;"><h3 class="BlockTitle Recommendations-BlockTitle">推荐阅读</h3><ul class="Recommendations-List"><button class="PagingButton PagingButton-Previous" disabled=""><svg class="Zi Zi--ArrowLeft" fill="#d3d3d3" viewBox="0 0 24 24" width="40" height="40"><path d="M14.782 16.78a.737.737 0 0 1-1.052 0L9.218 12.53a.758.758 0 0 1 0-1.063L13.73 7.22a.737.737 0 0 1 1.052 0c.29.294.29.77.001 1.063L11 12l3.782 3.716c.29.294.29.77 0 1.063z" fill-rule="evenodd"></path></svg></button><a href="https://zhuanlan.zhihu.com/p/32626442" class="PostItem"><div><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-4a3b4a39ab8e5c556359147b882b4788_250x0.gif" srcset="https://pic4.zhimg.com/v2-4a3b4a39ab8e5c556359147b882b4788_qhd.gif 2x" class="PostItem-TitleImage" alt="从 SGD 到 Adam —— 深度学习优化算法概览(一)"><h1 class="PostItem-Title">从 SGD 到 Adam —— 深度学习优化算法概览(一)</h1><div class="PostItem-Footer"><span>骆梁宸</span><span class="PostItem-FooterTitle"></span></div></div></a><a href="https://zhuanlan.zhihu.com/p/48683826" class="PostItem"><div><h1 class="PostItem-Title">监督学习应用梯度下降</h1><p class="PostItem-Summary">看了新版的吴恩达机器学习视频（发布在网易云上的），然后再看老版的斯坦福CS229，感觉还是老版的内容更全更清楚；于是又打算看老版视频再学一遍，同时做个学习笔记。 机器学习其实就是研究…</p><div class="PostItem-Footer"><span>ZoeLa...</span><span class="PostItem-FooterTitle">发表于吴恩达机器...</span></div></div></a><a href="https://zhuanlan.zhihu.com/p/68423193" class="PostItem"><div><img src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-bbf9968f6bdb12e4bcb11841647b204d_250x0.jpg" srcset="https://pic4.zhimg.com/v2-bbf9968f6bdb12e4bcb11841647b204d_qhd.jpg 2x" class="PostItem-TitleImage" alt="从最大熵模型解释逻辑回归"><h1 class="PostItem-Title">从最大熵模型解释逻辑回归</h1><div class="PostItem-Footer"><span>silent</span><span class="PostItem-FooterTitle"></span></div></div></a><a href="https://zhuanlan.zhihu.com/p/31074506" class="PostItem"><div><h1 class="PostItem-Title">机器学习数学：梯度下降法</h1><p class="PostItem-Summary">前记：在刚开始写感知机时，发现有必要把梯度下降法拿出来单独起一篇。因为在往后的很多机器学习算法模型中求解损失函数的最小化问题都运用到了梯度下降法。 ps：看到了之前写的文章的题图…</p><div class="PostItem-Footer"><span>岭大王</span><span class="PostItem-FooterTitle"></span></div></div></a><button class="PagingButton PagingButton-Next"><svg class="Zi Zi--ArrowRight" fill="#d3d3d3" viewBox="0 0 24 24" width="40" height="40"><path d="M9.218 16.78a.737.737 0 0 0 1.052 0l4.512-4.249a.758.758 0 0 0 0-1.063L10.27 7.22a.737.737 0 0 0-1.052 0 .759.759 0 0 0-.001 1.063L13 12l-3.782 3.716a.758.758 0 0 0 0 1.063z" fill-rule="evenodd"></path></svg></button></ul></div><div class="Comments-container" data-za-detail-view-path-module="CommentList" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:null}}"><div class="CommentsV2 CommentsV2--withEditor CommentsV2-withPagination"><div class="Topbar CommentTopbar"><div class="Topbar-title"><h2 class="CommentTopbar-title">47 条评论</h2></div><div class="Topbar-options"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Switch Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M13.004 7V4.232c0-.405.35-.733.781-.733.183 0 .36.06.501.17l6.437 5.033c.331.26.376.722.1 1.033a.803.803 0 0 1-.601.264H2.75a.75.75 0 0 1-.75-.75V7.75A.75.75 0 0 1 2.75 7h10.254zm-1.997 9.999v2.768c0 .405-.35.733-.782.733a.814.814 0 0 1-.5-.17l-6.437-5.034a.702.702 0 0 1-.1-1.032.803.803 0 0 1 .6-.264H21.25a.75.75 0 0 1 .75.75v1.499a.75.75 0 0 1-.75.75H11.007z" fill-rule="evenodd"></path></svg></span>切换为时间排序</button></div></div><div class="CommentsV2-footer CommentEditorV2--normal"><div class="CommentEditorV2-inputWrap"><div class="CommentEditorV2-input Input-wrapper Input-wrapper--spread Input-wrapper--large Input-wrapper--noPadding"><div class="Input Editable"><div class="Dropzone RichText RichText--editable RichText--clearBoth ztext" style="min-height: 198px;"><div class="DraftEditor-root"><div class="public-DraftEditorPlaceholder-root"><div class="public-DraftEditorPlaceholder-inner" id="placeholder-bsn8u" style="white-space: pre-wrap;">写下你的评论...</div></div><div class="DraftEditor-editorContainer"><div aria-describedby="placeholder-bsn8u" class="notranslate public-DraftEditor-content" contenteditable="true" role="textbox" spellcheck="true" tabindex="0" style="outline: none; user-select: text; white-space: pre-wrap; overflow-wrap: break-word;"><div data-contents="true"><div class="Editable-unstyled" data-block="true" data-editor="bsn8u" data-offset-key="3mkqv-0-0"><div data-offset-key="3mkqv-0-0" class="public-DraftStyleDefault-block public-DraftStyleDefault-ltr"><span data-offset-key="3mkqv-0-0"><br data-text="true"></span></div></div></div></div></div></div></div><input multiple="" type="file" accept="image/jpg,image/jpeg,image/png,image/gif" style="display: none;"><div></div></div></div><div class="CommentEditorV2-inputUpload"><div class="CommentEditorV2-popoverWrap"><div class="Popover CommentEditorV2-inputUpLoad-Icon"><button aria-label="插入表情" data-tooltip="插入表情" data-tooltip-position="bottom" data-tooltip-will-hide-on-click="true" id="Popover15-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover15-content" type="button" class="Button Editable-control Button--plain"><svg class="Zi Zi--Emotion" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M7.523 13.5h8.954c-.228 2.47-2.145 4-4.477 4-2.332 0-4.25-1.53-4.477-4zM12 21a9 9 0 1 1 0-18 9 9 0 0 1 0 18zm0-1.5a7.5 7.5 0 1 0 0-15 7.5 7.5 0 0 0 0 15zm-3-8a1.5 1.5 0 1 1 0-3 1.5 1.5 0 0 1 0 3zm6 0a1.5 1.5 0 1 1 0-3 1.5 1.5 0 0 1 0 3z"></path></svg></button></div></div></div></div><button disabled="" type="button" class="Button CommentEditorV2-singleButton Button--primary Button--blue">发布</button></div><div><div class="CommentListV2"><ul class="NestComment"><li class="NestComment--rootComment"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover46-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover46-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/li-chen-5-19"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-a3db14da5d86504d4748fa4d2db9889e_s.jpg" srcset="https://pic2.zhimg.com/v2-a3db14da5d86504d4748fa4d2db9889e_xs.jpg 2x" alt="八八"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/li-chen-5-19">八八</a></span><span class="CommentItemV2-time">11 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>SGD的更新公式里的xn  yn 是不是 xi  yi ？</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover47-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover47-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/li-lee-6-7"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/da8e974dc_s.jpg" srcset="https://pic4.zhimg.com/da8e974dc_xs.jpg 2x" alt="急急如律令"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/li-lee-6-7">急急如律令</a></span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/li-chen-5-19">八八</a></span><span class="CommentItemV2-time">2 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>是的</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootComment"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover48-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover48-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/li-chen-5-19"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-a3db14da5d86504d4748fa4d2db9889e_s.jpg" srcset="https://pic2.zhimg.com/v2-a3db14da5d86504d4748fa4d2db9889e_xs.jpg 2x" alt="八八"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/li-chen-5-19">八八</a></span><span class="CommentItemV2-time">11 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>logistics regression 或许叫对数几率回归（对率回归）更合适</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>2</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover49-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover49-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/begeekmyfriend"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-ba7c7a1220f886a9cf5713133a8a7886_s.jpg" srcset="https://pic2.zhimg.com/v2-ba7c7a1220f886a9cf5713133a8a7886_xs.jpg 2x" alt="我的上铺叫路遥"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/begeekmyfriend">我的上铺叫路遥</a></span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/li-chen-5-19">八八</a></span><span class="CommentItemV2-time">11 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>根本不应该叫logistics regression，而是logistics classification</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>2</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover50-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover50-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/lawchihwei"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-bbbf6e3e7fd1f3ef6c13f615c32b2f20_s.jpg" srcset="https://pic4.zhimg.com/v2-bbbf6e3e7fd1f3ef6c13f615c32b2f20_xs.jpg 2x" alt="印掟"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/lawchihwei">印掟</a></span><span class="CommentItemV2-time">9 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">天哪写的太好了</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover51-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover51-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/ze-young"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/685d849f617e58ff94a3eaba00411b7b_s.jpg" srcset="https://pic3.zhimg.com/685d849f617e58ff94a3eaba00411b7b_xs.jpg 2x" alt="Youngzzz"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/ze-young">Youngzzz</a></span><span class="CommentItemV2-time">8 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>写的真是非常好，期待你新的内容</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover52-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover52-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/deng-gao-shan"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/83355acd2_s.jpg" srcset="https://pic1.zhimg.com/83355acd2_xs.jpg 2x" alt="折射"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/deng-gao-shan">折射</a></span><span class="CommentItemV2-roleInfo"> (作者) </span><span class="CommentItemV2-time">8 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">感谢支持！</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootComment"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover53-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover53-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/yang-mu-zhi-77"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-5164a9a33c05e02e08a0bf66f86a9027_s.jpg" srcset="https://pic2.zhimg.com/v2-5164a9a33c05e02e08a0bf66f86a9027_xs.jpg 2x" alt="杨木之"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/yang-mu-zhi-77">杨木之</a></span><span class="CommentItemV2-time">8 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">其他的地方写的特别好，就是在使用最大似然的时候，直接引出最大似然是为了说明存在的事件也就是收集到的样本的概率最大，然后利用概率的乘法公式求出概率，使得概率最大会好点，引入损失函数这个会变成最大化损失，与其他机器学习算法，损失最小相违背，这是我的观点，请指教，</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover54-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover54-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/deng-gao-shan"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/83355acd2_s.jpg" srcset="https://pic1.zhimg.com/83355acd2_xs.jpg 2x" alt="折射"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/deng-gao-shan">折射</a></span><span class="CommentItemV2-roleInfo"> (作者) </span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/yang-mu-zhi-77">杨木之</a></span><span class="CommentItemV2-time">8 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">损失函数可以定义为原函数加个负号，这样就能与其他机器学习模型统一。</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover55-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover55-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/yang-song-yang"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-dd1fd4603c804f66f6a3d5157cf5af3f_s.jpg" srcset="https://pic4.zhimg.com/v2-dd1fd4603c804f66f6a3d5157cf5af3f_xs.jpg 2x" alt="羊送羊"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/yang-song-yang">羊送羊</a></span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/deng-gao-shan">折射</a></span><span class="CommentItemV2-roleInfo"> (作者) </span><span class="CommentItemV2-time">5 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>写得很好，我觉得这里loss function应该从cross entropy切入更佳</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><div><div class="CommentMoreReplyButton"><button type="button" class="Button Button--plain">展开其他 2 条回复</button></div></div></ul><ul class="NestComment"><li class="NestComment--rootComment"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover56-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover56-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/liang-tong-39"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/d8a0d3c12_s.jpg" srcset="https://pic3.zhimg.com/d8a0d3c12_xs.jpg 2x" alt="肚肚排"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/liang-tong-39">肚肚排</a></span><span class="CommentItemV2-time">7 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>推导过程非常清晰，有点小疑问，既然是最大似然估计，那就是要求最大的损失函数，应该是叫梯度上升吧</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover57-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover57-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/yang-song-yang"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-dd1fd4603c804f66f6a3d5157cf5af3f_s.jpg" srcset="https://pic4.zhimg.com/v2-dd1fd4603c804f66f6a3d5157cf5af3f_xs.jpg 2x" alt="羊送羊"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/yang-song-yang">羊送羊</a></span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/liang-tong-39">肚肚排</a></span><span class="CommentItemV2-time">5 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>文章里的loss function之前应该要加一个负号，所以在update W的时候作者用了+而不是-。</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover58-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover58-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/li-lee-6-7"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/da8e974dc_s.jpg" srcset="https://pic4.zhimg.com/da8e974dc_xs.jpg 2x" alt="急急如律令"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/li-lee-6-7">急急如律令</a></span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/liang-tong-39">肚肚排</a></span><span class="CommentItemV2-time">2 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>是的，可以直接用梯度上升去做。但一般为了统一做法（一般cost都是求最小），此时，通过将最大似然求最大，通过乘一个负数，求负的最小，两者等效起来。此时，求这个负的最小，就可以用梯度下降。</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover59-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover59-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/heng-xing-13"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-66d08c4aa4767d1368ef870e93d07ef1_s.jpg" srcset="https://pic1.zhimg.com/v2-66d08c4aa4767d1368ef870e93d07ef1_xs.jpg 2x" alt="亨行"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/heng-xing-13">亨行</a></span><span class="CommentItemV2-time">7 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>写的太好了吧，感谢！</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover60-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover60-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/qiu-bo-52-56"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/07feb433ddd270b9c77f34dc0fa7c1a0_s.jpg" srcset="https://pic1.zhimg.com/07feb433ddd270b9c77f34dc0fa7c1a0_xs.jpg 2x" alt="邱波"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/qiu-bo-52-56">邱波</a></span><span class="CommentItemV2-time">7 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">理解透彻，厉害了，话说损失函数那加个负号，求使损失函数最小的w，就更加清晰了。</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover61-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover61-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/chen-xiao-ting-80-19"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-82daf83a26ec68cc4d729592450fb9df_s.jpg" srcset="https://pic1.zhimg.com/v2-82daf83a26ec68cc4d729592450fb9df_xs.jpg 2x" alt="呆萌兔"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/chen-xiao-ting-80-19">呆萌兔</a></span><span class="CommentItemV2-time">5 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>十分感谢作者！一个小时弄得明明白白！</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover62-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover62-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/yuan-ha-ha-28"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-a5ccf86553ba658193a04b0d988009ee_s.jpg" srcset="https://pic3.zhimg.com/v2-a5ccf86553ba658193a04b0d988009ee_xs.jpg 2x" alt="袁哈哈"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/yuan-ha-ha-28">袁哈哈</a></span><span class="CommentItemV2-time">5 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">很棒 写的很清楚了</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover63-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover63-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/xbsun-5"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-650281cd8dddcef76850406a50d757fc_s.jpg" srcset="https://pic4.zhimg.com/v2-650281cd8dddcef76850406a50d757fc_xs.jpg 2x" alt="xbsun"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/xbsun-5">xbsun</a></span><span class="CommentItemV2-time">5 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">支持，不过建议参见cs229资料，加入指数族分布，广义线性模型的内容，这样的话能更深入的理解sigmoid公式的来龙去脉</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootComment"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover64-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover64-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/213124-29"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-4d34498d87d0d18f4c7deb3e6016fb56_s.jpg" srcset="https://pic1.zhimg.com/v2-4d34498d87d0d18f4c7deb3e6016fb56_xs.jpg 2x" alt="臧小波"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/213124-29">臧小波</a></span><span class="CommentItemV2-time">5 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">请问我能转到博客吗，会标明出处的，写的太好了</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover65-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover65-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/deng-gao-shan"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/83355acd2_s.jpg" srcset="https://pic1.zhimg.com/83355acd2_xs.jpg 2x" alt="折射"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/deng-gao-shan">折射</a></span><span class="CommentItemV2-roleInfo"> (作者) </span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/213124-29">臧小波</a></span><span class="CommentItemV2-time">5 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">好的</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootComment"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover66-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover66-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhu-zi-kang-35"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/da8e974dc_s.jpg" srcset="https://pic4.zhimg.com/da8e974dc_xs.jpg 2x" alt="zhu2900000"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhu-zi-kang-35">zhu2900000</a></span><span class="CommentItemV2-time">5 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">感谢。损失函数 f（w）怎么体现损失的？训练标签y*当前模型预测概率ln（p），这两项相乘是的很么意思</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover67-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover67-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhu-zi-kang-35"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/da8e974dc_s.jpg" srcset="https://pic4.zhimg.com/da8e974dc_xs.jpg 2x" alt="zhu2900000"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhu-zi-kang-35">zhu2900000</a></span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhu-zi-kang-35">zhu2900000</a></span><span class="CommentItemV2-time">5 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">明白了，损失函数的核心还是激活函数，P一个数字即表达了事件发生的可能性，即反应了与标签的差距，相比最小二乘难理解一些，但效果是一样的。</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover68-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover68-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/chen-xian-wang"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-d9fccb22d26f8df5a2d2568f8dcdc217_s.jpg" srcset="https://pic3.zhimg.com/v2-d9fccb22d26f8df5a2d2568f8dcdc217_xs.jpg 2x" alt="红色石头"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/chen-xian-wang">红色石头</a></span><span class="CommentItemV2-time">5 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>文中梯度公式里的p的表达式里的w*x部分不应该有下标吧？</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover69-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover69-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/da-xiong-50-47-51"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/da8e974dc_s.jpg" srcset="https://pic4.zhimg.com/da8e974dc_xs.jpg 2x" alt="大雄"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/da-xiong-50-47-51">大雄</a></span><span class="CommentItemV2-time">5 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>太棒了，还没看完，回家了再看看</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover70-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover70-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/you-mu-chen"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/5f42d85196e1072dc5bb1fcef46a6438_s.jpg" srcset="https://pic4.zhimg.com/5f42d85196e1072dc5bb1fcef46a6438_xs.jpg 2x" alt="葛溪驿"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/you-mu-chen">葛溪驿</a></span><span class="CommentItemV2-time">4 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">很赞👍👍👍👍</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootComment"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover71-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover71-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/shi-kai-27-20"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-eb0ddb2b52271ff30e944fa08c98d8ce_s.jpg" srcset="https://pic4.zhimg.com/v2-eb0ddb2b52271ff30e944fa08c98d8ce_xs.jpg 2x" alt="数据之眼"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/shi-kai-27-20">数据之眼</a></span><span class="CommentItemV2-time">4 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">感觉极大似然估计哪里是不是用错对象了，我没听说过针对所有样本输出概率之积做最大似然估计的，理论上也说不通，但是后面又改回来了</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover72-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover72-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/deng-gao-shan"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/83355acd2_s.jpg" srcset="https://pic1.zhimg.com/83355acd2_xs.jpg 2x" alt="折射"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/deng-gao-shan">折射</a></span><span class="CommentItemV2-roleInfo"> (作者) </span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/shi-kai-27-20">数据之眼</a></span><span class="CommentItemV2-time">4 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">emmm，你说的后面又改回来了，指的是取对数把连乘变成连加吗。。。</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover73-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover73-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/shi-kai-27-20"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-eb0ddb2b52271ff30e944fa08c98d8ce_s.jpg" srcset="https://pic4.zhimg.com/v2-eb0ddb2b52271ff30e944fa08c98d8ce_xs.jpg 2x" alt="数据之眼"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/shi-kai-27-20">数据之眼</a></span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/deng-gao-shan">折射</a></span><span class="CommentItemV2-roleInfo"> (作者) </span><span class="CommentItemV2-time">4 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">我搞错了吧，一般说最大似然函数是损失函数，你这里定义成目标函数</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover74-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover74-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/papipipa"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-d5c3f832055aa39e5ec6b2474abc9e48_s.jpg" srcset="https://pic2.zhimg.com/v2-d5c3f832055aa39e5ec6b2474abc9e48_xs.jpg 2x" alt="婉儿飞飞"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/papipipa">婉儿飞飞</a></span><span class="CommentItemV2-time">4 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">这个终于解释清楚了p^y * (1-p)p^(1-y)y</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover75-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover75-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-zi-han-86-31"><img class="Avatar UserLink-avatar" width="24" height="24" src="./逻辑回归 logistics regression 公式推导 - 知乎_files/v2-b9d147aa4f4f99121476af49674ddbfc_s.jpg" srcset="https://pic1.zhimg.com/v2-b9d147aa4f4f99121476af49674ddbfc_xs.jpg 2x" alt="Will"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-zi-han-86-31">Will</a></span><span class="CommentItemV2-time">4 个月前</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>学习了，有收获，谢谢</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul></div><div class="Pagination CommentsV2-pagination"><button disabled="" type="button" class="Button PaginationButton PaginationButton--current Button--plain">1</button><button type="button" class="Button PaginationButton Button--plain">2</button><button type="button" class="Button PaginationButton PaginationButton-next Button--plain">下一页</button></div><span></span></div></div></div></div></div></main><div class="CornerButtons"><div class="CornerAnimayedFlex"><button data-tooltip="建议反馈" data-tooltip-position="left" data-tooltip-will-hide-on-click="true" aria-label="建议反馈" type="button" class="Button CornerButton Button--plain"><svg class="Zi Zi--Feedback" title="建议反馈" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M19.99 6.99L18 5s-1-1-2-1H8C7 4 6 5 6 5L4 7S3 8 3 9v9s0 2 2.002 2H19c2 0 2-2 2-2V9c0-1-1.01-2.01-1.01-2.01zM16.5 5.5L19 8H5l2.5-2.5h9zm-2 5.5s.5 0 .5.5-.5.5-.5.5h-5s-.5 0-.5-.5.5-.5.5-.5h5z"></path></svg></button></div><div class="CornerAnimayedFlex CornerAnimayedFlex--hidden"><button data-tooltip="回到顶部" data-tooltip-position="left" data-tooltip-will-hide-on-click="true" aria-label="回到顶部" type="button" class="Button CornerButton Button--plain"><svg class="Zi Zi--BackToTop" title="回到顶部" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M16.036 19.59a1 1 0 0 1-.997.995H9.032a.996.996 0 0 1-.997-.996v-7.005H5.03c-1.1 0-1.36-.633-.578-1.416L11.33 4.29a1.003 1.003 0 0 1 1.412 0l6.878 6.88c.782.78.523 1.415-.58 1.415h-3.004v7.005z"></path></svg></button></div></div></div></div><script id="js-clientConfig" type="text/json">{"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","zhuanlanHost":"zhuanlan.zhihu.com","apiHost":"api.zhihu.com"}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false}},"entities":{"users":{"0f4e368fc584d10034f416ab5f93a4c0":{"uid":746340876615159800,"userType":"people","id":"0f4e368fc584d10034f416ab5f93a4c0"},"deng-gao-shan":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002F83355acd2_{size}.jpg","uid":"34924002279424","userType":"people","isFollowing":false,"urlToken":"deng-gao-shan","id":"f9607e8cf258e53b7c206ed7bcdf88db","description":"哈哈哈哈知乎上的沙雕网友实在是太有才了","name":"折射","isAdvertiser":false,"headline":"","gender":1,"url":"\u002Fpeople\u002Ff9607e8cf258e53b7c206ed7bcdf88db","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002F83355acd2_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"南加州大学 计算机科学硕士在读"}],"exposedMedal":{"medalId":"972475023013875712","medalName":"有口皆碑","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-7bc9ac329b296268bbd1e372c2589967_r.png","miniAvatarUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-b530054e49c93f8888cbdc743f4878b0_is.png","description":"获得 10000 个赞同"}}},"questions":{},"answers":{},"articles":{"44591359":{"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fpage_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=BiBUKF0xBSkqGGdRAWB0Blh8OvuEwv2m92E=&idfa=__IDFA__&imei=__IMEI__&androidid=__ANDROIDID__"],"id":44591359,"title":"逻辑回归 logistics regression 公式推导","type":"article","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F44591359","imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-c7d295979e8d98ade8a93ae34ddc6320_b.jpg","titleImage":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-c7d295979e8d98ade8a93ae34ddc6320_b.jpg","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ab82d755dba95f0585678fe2d4af28d6_200x112.png\" data-caption=\"sigmoid函数\" data-size=\"normal\" data-rawwidth=\"468\" data-rawheight=\"167\" data-watermark=\"original\" data-original-src=\"v2-ab82d755dba95f0585678fe2d4af28d6\" data-watermark-src=\"v2-5bf1c30a134a18a53e0092f51fb41b78\" data-private-watermark-src=\"\" class=\"origin_image inline-img zh-lightbox-thumb\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ab82d755dba95f0585678fe2d4af28d6_r.png\"\u002F\u003E原创，转载请注明出处。（常规字母代表标量，粗体字母代表向量，大写粗体字母代表矩阵） 逻辑回归虽然名字里面有回归，但是主要用来解决分类问题。 \u003Cb\u003E一、线性回归（Linear Regression）\u003C\u002Fb\u003E线性回归的表达式：f(\\bm{x}) = \\bm{w}^T\\bm{x} + b线性回归对于给定的…","created":1536994343,"updated":1563693479,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002F83355acd2_{size}.jpg","uid":"34924002279424","userType":"people","isFollowing":false,"urlToken":"deng-gao-shan","id":"f9607e8cf258e53b7c206ed7bcdf88db","description":"哈哈哈哈知乎上的沙雕网友实在是太有才了","name":"折射","isAdvertiser":false,"headline":"","gender":1,"url":"\u002Fpeople\u002Ff9607e8cf258e53b7c206ed7bcdf88db","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002F83355acd2_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"南加州大学 计算机科学硕士在读"}],"exposedMedal":{"medalId":"972475023013875712","medalName":"有口皆碑","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-7bc9ac329b296268bbd1e372c2589967_r.png","miniAvatarUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-b530054e49c93f8888cbdc743f4878b0_is.png","description":"获得 10000 个赞同"}},"commentPermission":"all","state":"published","imageWidth":1200,"imageHeight":630,"content":"\u003Cp\u003E原创，转载请注明出处。\u003C\u002Fp\u003E\u003Cp\u003E（常规字母代表标量，粗体字母代表向量，大写粗体字母代表矩阵）\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E逻辑回归虽然名字里面有回归，但是主要用来解决分类问题。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E一、线性回归（Linear Regression）\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E线性回归的表达式：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=f%28%5Cbm%7Bx%7D%29+%3D+%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D+%2B+b\" alt=\"f(\\bm{x}) = \\bm{w}^T\\bm{x} + b\" eeimg=\"1\"\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E线性回归对于给定的输入 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bx%7D\" alt=\"\\bm{x}\" eeimg=\"1\"\u002F\u003E ，输出的是一个数值 y ，因此它是一个解决回归问题的模型。\u003C\u002Fp\u003E\u003Cp\u003E为了消除掉后面的常数项b，我们可以令 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbegin%7Bmatrix%7D+%5Cbm%7Bx%7D%5E%7B%27%7D+%26%3D+%5B+1+%26+%5Cbm%7Bx%7D%5D%5ET++%5Cend%7Bmatrix%7D\" alt=\"\\begin{matrix} \\bm{x}^{&#39;} &amp;= [ 1 &amp; \\bm{x}]^T  \\end{matrix}\" eeimg=\"1\"\u002F\u003E ，同时 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbegin%7Bmatrix%7D+%5Cbm%7Bw%7D%5E%7B%27%7D+%26%3D+%5B+b+%26+%5Cbm%7Bw%7D%5D%5ET+%5Cend%7Bmatrix%7D\" alt=\"\\begin{matrix} \\bm{w}^{&#39;} &amp;= [ b &amp; \\bm{w}]^T \\end{matrix}\" eeimg=\"1\"\u002F\u003E ，也就是说给x多加一项而且值恒为1，这样b就到了w里面去了，直线方程可以化简成为：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=f%28%5Cbm%7Bx%27%7D%29+%3D+%5Cbm%7Bw%27%7D%5ET%5Cbm%7Bx%27%7D+\" alt=\"f(\\bm{x&#39;}) = \\bm{w&#39;}^T\\bm{x&#39;} \" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E在接下来的文章中为了方便，我们所使用的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D%2C%5Cbm%7Bx%7D\" alt=\"\\bm{w},\\bm{x}\" eeimg=\"1\"\u002F\u003E 其实指代的是 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=w%27%2Cx%27\" alt=\"w&#39;,x&#39;\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E二、分类问题（Classification）\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E二分类问题就是给定的输入 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bx%7D\" alt=\"\\bm{x}\" eeimg=\"1\"\u002F\u003E，判断它的标签是A类还是类。二分类问题是最简单的分类问题。我们可以把多分类问题转化成一组二分类问题。比如最简单的是OVA(One-vs-all)方法，比如一个10分类问题，我们可以分别判断输入 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bx%7D\" alt=\"\\bm{x}\" eeimg=\"1\"\u002F\u003E 是否属于某个类，从而转换成10个二分类问题。\u003C\u002Fp\u003E\u003Cp\u003E因此，解决了二分类问题，相当于解决了多分类问题。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E三、如何用连续的数值去预测离散的标签值呢？\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E线性回归的输出是一个数值，而不是一个标签，显然不能直接解决二分类问题。那我如何改进我们的回归模型来预测标签呢？\u003C\u002Fp\u003E\u003Cp\u003E一个最直观的办法就是设定一个阈值，比如0，如果我们预测的数值 y &gt; 0 ，那么属于标签A，反之属于标签B，采用这种方法的模型又叫做\u003Cb\u003E感知机\u003C\u002Fb\u003E（Perceptron）。\u003C\u002Fp\u003E\u003Cp\u003E另一种方法，我们不去直接预测标签，而是去预测标签为A概率，我们知道概率是一个[0,1]区间的连续数值，那我们的输出的数值就是标签为A的概率。一般的如果标签为A的概率大于0.5，我们就认为它是A类，否则就是B类。这就是我们的这次的主角\u003Cb\u003E逻辑回归模型 \u003C\u002Fb\u003E(Logistics Regression)。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E四、逻辑回归（logistics regression）\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E明确了预测目标是标签为A的概率。\u003C\u002Fp\u003E\u003Cp\u003E我们知道，概率是属于[0,1]区间。但是线性模型 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=f%28%5Cbm%7Bx%7D%29+%3D+%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D\" alt=\"f(\\bm{x}) = \\bm{w}^T\\bm{x}\" eeimg=\"1\"\u002F\u003E 值域是 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%28-%5Cinfty%2C%5Cinfty%29\" alt=\"(-\\infty,\\infty)\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cp\u003E我们不能直接基于线性模型建模。需要找到一个模型的值域刚好在[0,1]区间，同时要足够好用。\u003C\u002Fp\u003E\u003Cp\u003E于是，选择了我们的sigmoid函数。\u003C\u002Fp\u003E\u003Cp\u003E它的表达式为： \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Csigma%28x%29+%3D%5Cfrac%7B1%7D%7B1%2Be%5E%7B-x%7D%7D\" alt=\"\\sigma(x) =\\frac{1}{1+e^{-x}}\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cp\u003E它的图像：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ab82d755dba95f0585678fe2d4af28d6_b.jpg\" data-size=\"normal\" data-rawwidth=\"468\" data-rawheight=\"167\" class=\"origin_image zh-lightbox-thumb\" width=\"468\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ab82d755dba95f0585678fe2d4af28d6_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;468&#39; height=&#39;167&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"468\" data-rawheight=\"167\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"468\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ab82d755dba95f0585678fe2d4af28d6_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ab82d755dba95f0585678fe2d4af28d6_b.jpg\"\u002F\u003E\u003Cfigcaption\u003Esigmoid函数\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E这个函数的有很多非常好的性质，一会儿你就会感受到。但是我们不能直接拿了sigmoid函数就用，毕竟它连要训练的参数 w 都没得。\u003C\u002Fp\u003E\u003Cp\u003E我们结合sigmoid函数，线性回归函数，把线性回归模型的输出作为sigmoid函数的输入。于是最后就变成了逻辑回归模型：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=y%3D%5Csigma%28f%28%5Cbm%7Bx%7D%29%29+%3D+%5Csigma%28%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%29%3D%5Cfrac%7B1%7D%7B1%2Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%7D%7D\" alt=\"y=\\sigma(f(\\bm{x})) = \\sigma(\\bm{w}^T\\bm{x})=\\frac{1}{1+e^{-\\bm{w}^T\\bm{x}}}\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E假设我们已经训练好了一组权值 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D%5ET\" alt=\"\\bm{w}^T\" eeimg=\"1\"\u002F\u003E 。只要把我们需要预测的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bx%7D\" alt=\"\\bm{x}\" eeimg=\"1\"\u002F\u003E 代入到上面的方程，输出的y值就是这个标签为A的概率，我们就能够判断输入数据是属于哪个类别。\u003C\u002Fp\u003E\u003Cp\u003E接下来就来详细介绍，如何利用一组采集到的真实样本，训练出参数w的值。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E五、逻辑回归的损失函数（Loss Function）\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E损失函数就是用来衡量模型的输出与真实输出的差别。\u003C\u002Fp\u003E\u003Cp\u003E假设只有两个标签1和0， \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=y_n+%5Cin%5C%7B0%2C+1%5C%7D\" alt=\"y_n \\in\\{0, 1\\}\" eeimg=\"1\"\u002F\u003E 。我们把采集到的任何一组样本看做一个事件的话，那么这个事件发生的概率假设为p。我们的模型y的值等于标签为1的概率也就是p。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=P_%7By%3D1%7D%3D%5Cfrac%7B1%7D%7B1%2Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%7D%7D+%3D+p\" alt=\"P_{y=1}=\\frac{1}{1+e^{-\\bm{w}^T\\bm{x}}} = p\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E因为标签不是1就是0，因此标签为0的概率就是： \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=P_%7By%3D0%7D+%3D+1-p\" alt=\"P_{y=0} = 1-p\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cp\u003E我们把单个样本看做一个事件，那么这个事件发生的概率就是：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=P%28y%7C%5Cbm%7Bx%7D%29%3D%5Cleft%5C%7B+%5Cbegin%7Baligned%7D+p%2C+y%3D1+%5C%5C+1-p%2Cy%3D0+%5Cend%7Baligned%7D+%5Cright.\" alt=\"P(y|\\bm{x})=\\left\\{ \\begin{aligned} p, y=1 \\\\ 1-p,y=0 \\end{aligned} \\right.\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E这个函数不方便计算，它等价于:\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=P%28y_i%7C%5Cbm%7Bx%7D_i%29+%3D+p%5E%7By_i%7D%281-p%29%5E%7B1-%7By_i%7D%7D\" alt=\"P(y_i|\\bm{x}_i) = p^{y_i}(1-p)^{1-{y_i}}\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cp\u003E解释下这个函数的含义，我们采集到了一个样本 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%28%5Cbm%7Bx_i%7D%2Cy_i%29\" alt=\"(\\bm{x_i},y_i)\" eeimg=\"1\"\u002F\u003E 。对这个样本，它的标签是 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=y_i\" alt=\"y_i\" eeimg=\"1\"\u002F\u003E 的概率是 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=p%5E%7By_i%7D%281-p%29%5E%7B1-%7By_i%7D%7D\" alt=\"p^{y_i}(1-p)^{1-{y_i}}\" eeimg=\"1\"\u002F\u003E 。 （当y=1，结果是p；当y=0，结果是1-p）。\u003C\u002Fp\u003E\u003Cp\u003E如果我们采集到了一组数据一共N个， \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5C%7B%28%5Cbm%7Bx%7D_1%2Cy_1%29%2C%28%5Cbm%7Bx%7D_2%2Cy_2%29%2C%28%5Cbm%7Bx%7D_3%2Cy_3%29...%28%5Cbm%7Bx%7D_N%2Cy_N%29%5C%7D\" alt=\"\\{(\\bm{x}_1,y_1),(\\bm{x}_2,y_2),(\\bm{x}_3,y_3)...(\\bm{x}_N,y_N)\\}\" eeimg=\"1\"\u002F\u003E ，这个合成在一起的合事件发生的总概率怎么求呢？其实就是将每一个样本发生的概率相乘就可以了，即采集到这组样本的概率：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbegin%7Baligned%7D+P_%7B%E6%80%BB%7D+%26%3D+P%28y_1%7C%5Cbm%7Bx%7D_1%29P%28y_2%7C%5Cbm%7Bx%7D_2%29P%28y_3%7C%5Cbm%7Bx%7D_3%29....P%28y_N%7C%5Cbm%7Bx%7D_N%29+%5C%5C++%26%3D+%5Cprod_%7Bn%3D1%7D%5E%7BN%7Dp%5E%7By_n%7D%281-p%29%5E%7B1-y_n%7D++%5Cend%7Baligned%7D\" alt=\"\\begin{aligned} P_{总} &amp;= P(y_1|\\bm{x}_1)P(y_2|\\bm{x}_2)P(y_3|\\bm{x}_3)....P(y_N|\\bm{x}_N) \\\\  &amp;= \\prod_{n=1}^{N}p^{y_n}(1-p)^{1-y_n}  \\end{aligned}\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E注意\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=P_%7B%E6%80%BB+%7D\" alt=\"P_{总 }\" eeimg=\"1\"\u002F\u003E 是一个函数，并且未知的量只有 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D\" alt=\"\\bm{w}\" eeimg=\"1\"\u002F\u003E （在p里面）。\u003C\u002Fp\u003E\u003Cp\u003E由于连乘很复杂，我们通过两边取对数来把连乘变成连加的形式，即：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbegin%7Baligned%7D+F%28%5Cbm%7Bw%7D%29%3Dln%28P_%7B%E6%80%BB%7D+%29++%26%3D+ln%28%5Cprod_%7Bn%3D1%7D%5E%7BN%7Dp%5E%7By_n%7D%281-p%29%5E%7B1-y_n%7D+%29+%5C%5C+%26%3D+%5Csum_%7Bn%3D1%7D%5E%7BN%7Dln+%28p%5E%7By_n%7D%281-p%29%5E%7B1-y_n%7D%29+%5C%5C+%26%3D+%5Csum_%7Bn%3D1%7D%5E%7BN%7D%28y_n+ln+%28p%29+%2B+%281-y_n%29ln%281-p%29%29+%5Cend%7Baligned%7D+\" alt=\"\\begin{aligned} F(\\bm{w})=ln(P_{总} )  &amp;= ln(\\prod_{n=1}^{N}p^{y_n}(1-p)^{1-y_n} ) \\\\ &amp;= \\sum_{n=1}^{N}ln (p^{y_n}(1-p)^{1-y_n}) \\\\ &amp;= \\sum_{n=1}^{N}(y_n ln (p) + (1-y_n)ln(1-p)) \\end{aligned} \" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E其中， \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=p+%3D+%5Cfrac%7B1%7D%7B1%2Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%7D%7D+\" alt=\"p = \\frac{1}{1+e^{-\\bm{w}^T\\bm{x}}} \" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E这个函数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=F%28%5Cbm%7Bw%7D%29\" alt=\"F(\\bm{w})\" eeimg=\"1\"\u002F\u003E  又叫做它的\u003Cb\u003E损失函数\u003C\u002Fb\u003E。损失函数可以理解成衡量我们当前的模型的输出结果，跟实际的输出结果之间的差距的一种函数。这里的损失函数的值等于事件发生的总概率，我们希望它越大越好。但是跟损失的含义有点儿违背，因此也可以在前面取个负号。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E六、最大似然估计MLE(Maximum Likelihood Estimation)\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E我们在真实世界中并不能直接看到概率是多少，我们只能观测到事件是否发生。也就是说，我们只能知道一个样本它实际的标签是1还是0。那么我们如何估计参数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D\" alt=\"\\bm{w}\" eeimg=\"1\"\u002F\u003E 跟b的值呢？\u003C\u002Fp\u003E\u003Cp\u003E最大似然估计MLE(Maximum Likelihood Estimation)，就是一种估计参数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D\" alt=\"\\bm{w}\" eeimg=\"1\"\u002F\u003E 的方法。在这里如何使用MLE来估计 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D\" alt=\"\\bm{w}\" eeimg=\"1\"\u002F\u003E 呢？\u003C\u002Fp\u003E\u003Cp\u003E在上一节，我们知道损失函数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=F%EF%BC%88%5Cbm%7Bw%7D%EF%BC%89\" alt=\"F（\\bm{w}）\" eeimg=\"1\"\u002F\u003E 是正比于总概率 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=P_%7B%E6%80%BB%7D\" alt=\"P_{总}\" eeimg=\"1\"\u002F\u003E 的，而 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=F%EF%BC%88%5Cbm%7Bw%7D%EF%BC%89\" alt=\"F（\\bm{w}）\" eeimg=\"1\"\u002F\u003E 又只有一个变量 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D\" alt=\"\\bm{w}\" eeimg=\"1\"\u002F\u003E 。也就是说，通过改变 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D\" alt=\"\\bm{w}\" eeimg=\"1\"\u002F\u003E 的值，就能得到不同的总概率值 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=P_%7B%E6%80%BB%7D\" alt=\"P_{总}\" eeimg=\"1\"\u002F\u003E 。那么当我们选取的某个 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D%5E%2A\" alt=\"\\bm{w}^*\" eeimg=\"1\"\u002F\u003E 刚好使得总概率 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=P_%7B%E6%80%BB%7D\" alt=\"P_{总}\" eeimg=\"1\"\u002F\u003E 取得最大值的时候。我们就认为这个 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D%5E%2A\" alt=\"\\bm{w}^*\" eeimg=\"1\"\u002F\u003E 就是我们要求得的 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D\" alt=\"\\bm{w}\" eeimg=\"1\"\u002F\u003E 的值，这就是最大似然估计的思想。\u003C\u002Fp\u003E\u003Cp\u003E现在我们的问题变成了，找到一个 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D%5E%2A\" alt=\"\\bm{w}^*\" eeimg=\"1\"\u002F\u003E ，使得我们的总事件发生的概率，即损失函数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=F%EF%BC%88%5Cbm%7Bw%7D%EF%BC%89\" alt=\"F（\\bm{w}）\" eeimg=\"1\"\u002F\u003E 取得最大值，这句话用数学语言表达就是：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%5E%2A%7D+%3D+arg%5Cmax_%7Bw%7DF%28%5Cbm%7Bw%7D%29+%3D+-arg%5Cmin_%7Bw%7DF%28%5Cbm%7Bw%7D%29+\" alt=\"\\bm{w^*} = arg\\max_{w}F(\\bm{w}) = -arg\\min_{w}F(\\bm{w}) \" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E七、 求\u003C\u002Fb\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=F%EF%BC%88%5Cbm%7Bw%7D%EF%BC%89\" alt=\"F（\\bm{w}）\" eeimg=\"1\"\u002F\u003E\u003Cb\u003E 的梯度\u003C\u002Fb\u003E \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cnabla+F%EF%BC%88%5Cbm%7Bw%7D%EF%BC%89\" alt=\"\\nabla F（\\bm{w}）\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E梯度的定义\u003C\u002Fb\u003E \u003C\u002Fp\u003E\u003Cp\u003E我们知道对于一个一维的标量x，它有导数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=x%27\" alt=\"x&#39;\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cp\u003E对一个多维的向量 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bx%7D+%3D+%28x_1%2Cx_2%2Cx_3%2C..%2Cx_n%29\" alt=\"\\bm{x} = (x_1,x_2,x_3,..,x_n)\" eeimg=\"1\"\u002F\u003E  来说，它的导数叫做梯度，也就是分别对于它的每个分量求导数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bx%7D%27+%3D+%28x_1%27%2Cx_2%27%2Cx_3%27%2C..%2Cx_n%27%29\" alt=\"\\bm{x}&#39; = (x_1&#39;,x_2&#39;,x_3&#39;,..,x_n&#39;)\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E接下来请拿出纸笔，一起动手来推导出 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cnabla+F%EF%BC%88%5Cbm%7Bw%7D%EF%BC%89\" alt=\"\\nabla F（\\bm{w}）\" eeimg=\"1\"\u002F\u003E 的表达式。请尽量尝试自己动手推导出来，如果哪一步不会了再看我的推导。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E七（二）、求梯度的推导过程\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E为了求出 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=F%EF%BC%88%5Cbm%7Bw%7D%EF%BC%89\" alt=\"F（\\bm{w}）\" eeimg=\"1\"\u002F\u003E的梯度\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cnabla+F%EF%BC%88%5Cbm%7Bw%7D%EF%BC%89\" alt=\"\\nabla F（\\bm{w}）\" eeimg=\"1\"\u002F\u003E，我们需要做一些准备工作。原谅我非常不喜欢看大串的数学公式，所以我尽可能用最简单的数学符号来描述。当然可能不够严谨，但是我觉得更容易看懂。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E首先，我们需要知道向量是如何求导的。具体的推导过程以及原理请参见 \u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fblog.csdn.net\u002Fmounty_fsc\u002Farticle\u002Fdetails\u002F51588794\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E矩阵求导\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cp\u003E我们只要记住几个结论就行了：对于一个矩阵 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7BA%7D\" alt=\"\\bm{A}\" eeimg=\"1\"\u002F\u003E 乘以一个向量的方程 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7BA%7D%5Cbm%7Bx%7D\" alt=\"\\bm{A}\\bm{x}\" eeimg=\"1\"\u002F\u003E ，对向量 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D\" alt=\"\\bm{w}\" eeimg=\"1\"\u002F\u003E 求导的结果是 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7BA%7D%5ET\" alt=\"\\bm{A}^T\" eeimg=\"1\"\u002F\u003E 。在这里我们把函数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7BA%7D%5Cbm%7Bx%7D\" alt=\"\\bm{A}\\bm{x}\" eeimg=\"1\"\u002F\u003E 对 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D\" alt=\"\\bm{w}\" eeimg=\"1\"\u002F\u003E 求梯度简单记作 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%EF%BC%88%5Cbm%7BA%7D%5Cbm%7Bx%7D%EF%BC%89%27\" alt=\"（\\bm{A}\\bm{x}）&#39;\" eeimg=\"1\"\u002F\u003E 。因此\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%EF%BC%88%5Cbm%7BA%7D%5Cbm%7Bx%7D%EF%BC%89%27+%3D+%5Cbm%7BA%7D%5ET\" alt=\"（\\bm{A}\\bm{x}）&#39; = \\bm{A}^T\" eeimg=\"1\"\u002F\u003E , 推论是 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%EF%BC%88%5Cbm%7Bx%7D%5ET%5Cbm%7BA%7D%EF%BC%89%27+%3D+%5Cbm%7BA%7D\" alt=\"（\\bm{x}^T\\bm{A}）&#39; = \\bm{A}\" eeimg=\"1\"\u002F\u003E ，我们把 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bx%7D%2C%5Cbm%7Bw%7D%5ET\" alt=\"\\bm{x},\\bm{w}^T\" eeimg=\"1\"\u002F\u003E 代入进去，可以知道 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%28%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%29%27+%3D+%5Cbm%7Bx%7D\" alt=\"(\\bm{w}^T\\bm{x})&#39; = \\bm{x}\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E然后求 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=1-p\" alt=\"1-p\" eeimg=\"1\"\u002F\u003E 的值：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=1-p%3D%5Cfrac%7Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%7D+%7D%7B+1%2Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%7D+%7D\" alt=\"1-p=\\frac{e^{-\\bm{w}^T\\bm{x}} }{ 1+e^{-\\bm{w}^T\\bm{x}} }\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003Ep是一个关于变量 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D\" alt=\"\\bm{w}\" eeimg=\"1\"\u002F\u003E 的函数，我们对p求导，通过链式求导法则，慢慢展开可以得：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbegin%7Baligned%7D++p%27+%3D+f%27%28%5Cbm%7Bw%7D%29%26%3D+%28%5Cfrac%7B1%7D%7B1%2Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%7D%7D+%29%27+%5C%5C+%26%3D+-%5Cfrac%7B1%7D%7B+%281%2Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%7D+%29%5E2%7D+++%C2%B7+%28+1%2Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%7D%29%27+%5C%5C+%26%3D+-%5Cfrac%7B1%7D%7B+%281%2Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%7D+%29%5E2%7D+++%C2%B7+e%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%7D++%C2%B7+%28-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%29%27+%5C%5C+%26%3D+-%5Cfrac%7B1%7D%7B+%281%2Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%7D+%29%5E2%7D+++%C2%B7+e%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%7D++%C2%B7+%28-%5Cbm%7Bx%7D+%29+%5C%5C+%26%3D+%5Cfrac%7Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%7D+%7D%7B+%281%2Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%7D+%29%5E2%7D+%C2%B7+++%5Cbm%7Bx%7D+%5C%5C+%26%3D++%5Cfrac%7B1%7D%7B+1%2Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%7D+%7D++++%C2%B7+%5Cfrac%7Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%7D+%7D%7B+1%2Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%7D+%7D++%C2%B7+%5Cbm%7Bx%7D+%5C%5C+%26%3D+p%281-p%29%5Cbm%7Bx%7D+%5Cend%7Baligned%7D\" alt=\"\\begin{aligned}  p&#39; = f&#39;(\\bm{w})&amp;= (\\frac{1}{1+e^{-\\bm{w}^T\\bm{x}}} )&#39; \\\\ &amp;= -\\frac{1}{ (1+e^{-\\bm{w}^T\\bm{x}} )^2}   · ( 1+e^{-\\bm{w}^T\\bm{x}})&#39; \\\\ &amp;= -\\frac{1}{ (1+e^{-\\bm{w}^T\\bm{x}} )^2}   · e^{-\\bm{w}^T\\bm{x}}  · (-\\bm{w}^T\\bm{x})&#39; \\\\ &amp;= -\\frac{1}{ (1+e^{-\\bm{w}^T\\bm{x}} )^2}   · e^{-\\bm{w}^T\\bm{x}}  · (-\\bm{x} ) \\\\ &amp;= \\frac{e^{-\\bm{w}^T\\bm{x}} }{ (1+e^{-\\bm{w}^T\\bm{x}} )^2} ·   \\bm{x} \\\\ &amp;=  \\frac{1}{ 1+e^{-\\bm{w}^T\\bm{x}} }    · \\frac{e^{-\\bm{w}^T\\bm{x}} }{ 1+e^{-\\bm{w}^T\\bm{x}} }  · \\bm{x} \\\\ &amp;= p(1-p)\\bm{x} \\end{aligned}\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E上面都是我们做的准备工作，总之我们得记住： \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=p%27+%3D+p%281-p%29%5Cbm%7Bx%7D\" alt=\"p&#39; = p(1-p)\\bm{x}\" eeimg=\"1\"\u002F\u003E , 并且可以知道 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%281-p%29%27+%3D+-p%281-p%29%5Cbm%7Bx%7D\" alt=\"(1-p)&#39; = -p(1-p)\\bm{x}\" eeimg=\"1\"\u002F\u003E 。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E下面我们正式开始对 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=F%28%5Cbm%7Bw%7D%29\" alt=\"F(\\bm{w})\" eeimg=\"1\"\u002F\u003E 求导，求导的时候请始终记住，我们的变量只有 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D\" alt=\"\\bm{w}\" eeimg=\"1\"\u002F\u003E ，其他的什么 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=y_n%2C%5Cbm%7Bx%7D_n+\" alt=\"y_n,\\bm{x}_n \" eeimg=\"1\"\u002F\u003E 都是已知的，可以看做常数。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbegin%7Baligned%7D+%5Cnabla+F%EF%BC%88%5Cbm%7Bw%7D%EF%BC%89%26+%3D+%5Cnabla+%EF%BC%88+%5Csum_%7Bn%3D1%7D%5E%7BN%7D%28y_n+ln+%28p%29+%2B+%281-y_n%29ln%281-p%29%29+%EF%BC%89%5C%5C+%26%3D+%5Csum+%28+y_n+ln%27%28p%29+%2B+%281-y_n%29+ln%27%281-p%29%29+%5C%5C+%26%3D+%5Csum%28+%28y_n+%5Cfrac%7B1%7D%7Bp%7Dp%27%29%2B%281-y_n%29%5Cfrac%7B1%7D%7B1-p%7D%281-p%29%27%29+%5C%5C+%26%3D+%5Csum%28y_n%281-p%29%5Cbm%7Bx%7D_n+-+%281-y_n%29p%5Cbm%7Bx%7D_n%29+%5C%5C+%26%3D+%5Csum_%7Bn%3D1%7D%5E%7BN%7D%7B%28y_n-p%29%5Cbm%7Bx%7D_n%7D+%5Cend%7Baligned%7D\" alt=\"\\begin{aligned} \\nabla F（\\bm{w}）&amp; = \\nabla （ \\sum_{n=1}^{N}(y_n ln (p) + (1-y_n)ln(1-p)) ）\\\\ &amp;= \\sum ( y_n ln&#39;(p) + (1-y_n) ln&#39;(1-p)) \\\\ &amp;= \\sum( (y_n \\frac{1}{p}p&#39;)+(1-y_n)\\frac{1}{1-p}(1-p)&#39;) \\\\ &amp;= \\sum(y_n(1-p)\\bm{x}_n - (1-y_n)p\\bm{x}_n) \\\\ &amp;= \\sum_{n=1}^{N}{(y_n-p)\\bm{x}_n} \\end{aligned}\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E终于，我们求出了梯度 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cnabla+F%EF%BC%88%5Cbm%7Bw%7D%EF%BC%89\" alt=\"\\nabla F（\\bm{w}）\" eeimg=\"1\"\u002F\u003E 的表达式了，现在我们再来看看它长什么样子：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbegin%7Baligned%7D+%5Cnabla+F%EF%BC%88%5Cbm%7Bw%7D%EF%BC%89%26%3D+%5Csum_%7Bn%3D1%7D%5E%7BN%7D%7B%28y_n-p%29%5Cbm%7Bx%7D_n%7D++%5Cend%7Baligned%7D\" alt=\"\\begin{aligned} \\nabla F（\\bm{w}）&amp;= \\sum_{n=1}^{N}{(y_n-p)\\bm{x}_n}  \\end{aligned}\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E它是如此简洁优雅，这就是我们选取sigmoid函数的原因之一。当然我们也能够把p再展开，即：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbegin%7Baligned%7D+%5Cnabla+F%EF%BC%88%5Cbm%7Bw%7D%EF%BC%89%26%3D++%5Csum_%7Bn%3D1%7D%5E%7BN%7D%7B%28y_n-+%5Cfrac%7B1%7D%7B1%2Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D_n%7D%7D+%29%5Cbm%7Bx%7D_n%7D+++%5Cend%7Baligned%7D\" alt=\"\\begin{aligned} \\nabla F（\\bm{w}）&amp;=  \\sum_{n=1}^{N}{(y_n- \\frac{1}{1+e^{-\\bm{w}^T\\bm{x}_n}} )\\bm{x}_n}   \\end{aligned}\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E八、梯度下降法（GD）与随机梯度下降法（SGD）\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E现在我们已经解出了损失函数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=+F%EF%BC%88%5Cbm%7Bw%7D%EF%BC%89\" alt=\" F（\\bm{w}）\" eeimg=\"1\"\u002F\u003E在任意 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D\" alt=\"\\bm{w}\" eeimg=\"1\"\u002F\u003E 处的梯度 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cnabla+F%EF%BC%88%5Cbm%7Bw%7D%EF%BC%89\" alt=\"\\nabla F（\\bm{w}）\" eeimg=\"1\"\u002F\u003E，可是我们怎么算出来 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%5E%2A%7D\" alt=\"\\bm{w^*}\" eeimg=\"1\"\u002F\u003E 呢？ 回到之前的问题，我们现在要求损失函数取最大值时候的\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%5E%2A%7D\" alt=\"\\bm{w^*}\" eeimg=\"1\"\u002F\u003E的值：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%5E%2A%7D+%3D+arg%5Cmax_%7Bw%7DF%28%5Cbm%7Bw%7D%29+\" alt=\"\\bm{w^*} = arg\\max_{w}F(\\bm{w}) \" eeimg=\"1\"\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E梯度下降法(Gradient Descent)\u003C\u002Fb\u003E，可以用来解决这个问题。核心思想就是先随便初始化一个 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D_0\" alt=\"\\bm{w}_0\" eeimg=\"1\"\u002F\u003E ，然后给定一个步长 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ceta\" alt=\"\\eta\" eeimg=\"1\"\u002F\u003E ，通过不断地修改 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D_%7Bt%2B1%7D+\" alt=\"\\bm{w}_{t+1} \" eeimg=\"1\"\u002F\u003E  &lt;- \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=+++%5Cbm%7Bw%7D_%7Bt%7D\" alt=\"   \\bm{w}_{t}\" eeimg=\"1\"\u002F\u003E ，从而最后靠近到达取得最大值的点，即不断进行下面的迭代过程，直到达到指定次数，或者梯度等于0为止。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D_%7Bt%2B1%7D+%3D+%5Cbm%7Bw%7D_t+%2B+%5Ceta%5Cnabla+F%EF%BC%88%5Cbm%7Bw%7D%EF%BC%89\" alt=\"\\bm{w}_{t+1} = \\bm{w}_t + \\eta\\nabla F（\\bm{w}）\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E随机梯度下降法（Stochastic Gradient Descent）\u003C\u002Fb\u003E，如果我们能够在每次更新过程中，加入一点点噪声扰动，可能会更加快速地逼近最优值。在SGD中，我们不直接使用 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cnabla+F%EF%BC%88%5Cbm%7Bw%7D%EF%BC%89\" alt=\"\\nabla F（\\bm{w}）\" eeimg=\"1\"\u002F\u003E ，而是采用另一个输出为随机变量的替代函数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=G%28%5Cbm%7Bw%7D%29\" alt=\"G(\\bm{w})\" eeimg=\"1\"\u002F\u003E :\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D_%7Bt%2B1%7D+%3D+%5Cbm%7Bw%7D_t+%2B+%5Ceta++G%28%5Cbm%7Bw%7D%29\" alt=\"\\bm{w}_{t+1} = \\bm{w}_t + \\eta  G(\\bm{w})\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E当然，这个替代函数 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=G%28%5Cbm%7Bw%7D%29\" alt=\"G(\\bm{w})\" eeimg=\"1\"\u002F\u003E需要满足它的期望值等于\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cnabla+F%EF%BC%88%5Cbm%7Bw%7D%EF%BC%89\" alt=\"\\nabla F（\\bm{w}）\" eeimg=\"1\"\u002F\u003E，相当于这个函数围绕着 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cnabla+F%EF%BC%88%5Cbm%7Bw%7D%EF%BC%89\" alt=\"\\nabla F（\\bm{w}）\" eeimg=\"1\"\u002F\u003E 的输出值随机波动。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E在这里我先解释一个问题：\u003Cb\u003E为什么可以用梯度下降法？\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E因为逻辑回归的损失函数L是一个连续的凸函数（conveniently convex）。这样的函数的特征是，它只会有一个全局最优的点，不存在局部最优。对于GD跟SGD最大的潜在问题就是它们可能会陷入局部最优。然而这个问题在逻辑回归里面就不存在了，因为它的损失函数的良好特性，导致它并不会有好几个局部最优。当我们的GD跟SGD收敛以后，我们得到的极值点一定就是全局最优的点，因此我们可以放心地用GD跟SGD来求解。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E好了，那我们要怎么实现学习算法呢？其实很简单，注意我们GD求导每次都耿直地用到了所有的样本点，从1一直到N都参与梯度计算。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbegin%7Baligned%7D+%5Cnabla+F%EF%BC%88%5Cbm%7Bw%7D%EF%BC%89%26%3D++%5Csum_%7Bn%3D1%7D%5E%7BN%7D%7B%28y_n-+%5Cfrac%7B1%7D%7B1%2Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D_n%7D%7D+%29%5Cbm%7Bx%7D_n%7D+%5Cend%7Baligned%7D\" alt=\"\\begin{aligned} \\nabla F（\\bm{w}）&amp;=  \\sum_{n=1}^{N}{(y_n- \\frac{1}{1+e^{-\\bm{w}^T\\bm{x}_n}} )\\bm{x}_n} \\end{aligned}\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E在SGD中，我们每次只要均匀地、随机选取其中一个样本 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%28%5Cbm%7Bx_i%7D%2Cy_i%29\" alt=\"(\\bm{x_i},y_i)\" eeimg=\"1\"\u002F\u003E ,用它代表整体样本，即把它的值乘以N，就相当于获得了梯度的无偏估计值，即 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=E%28G%28%5Cbm%7Bw%7D%29%29+%3D+%5Cnabla+F%28%5Cbm%7Bw%7D%29\" alt=\"E(G(\\bm{w})) = \\nabla F(\\bm{w})\" eeimg=\"1\"\u002F\u003E ，因此SGD的更新公式为：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D_%7Bt%2B1%7D+%3D+%5Cbm%7Bw%7D_t+%2B+%5Ceta++N++%7B%28y_n-+%5Cfrac%7B1%7D%7B1%2Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D_n%7D%7D+%29%5Cbm%7Bx%7D_n%7D\" alt=\"\\bm{w}_{t+1} = \\bm{w}_t + \\eta  N  {(y_n- \\frac{1}{1+e^{-\\bm{w}^T\\bm{x}_n}} )\\bm{x}_n}\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E这样我们前面的求和就没有了，同时 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ceta++N\" alt=\"\\eta  N\" eeimg=\"1\"\u002F\u003E 都是常数， \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=N\" alt=\"N\" eeimg=\"1\"\u002F\u003E 的值刚好可以并入 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Ceta+\" alt=\"\\eta \" eeimg=\"1\"\u002F\u003E  当中,因此SGD的迭代更新公式为：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D_%7Bt%2B1%7D+%3D+%5Cbm%7Bw%7D_t+%2B+%5Ceta+++%7B%28y_n-+%5Cfrac%7B1%7D%7B1%2Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D_n%7D%7D+%29%5Cbm%7Bx%7D_n%7D\" alt=\"\\bm{w}_{t+1} = \\bm{w}_t + \\eta   {(y_n- \\frac{1}{1+e^{-\\bm{w}^T\\bm{x}_n}} )\\bm{x}_n}\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E其中 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%28%5Cbm%7Bx_i%7D%2Cy_i%29\" alt=\"(\\bm{x_i},y_i)\" eeimg=\"1\"\u002F\u003E 是对所有样本随机抽样的一个结果。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E九、逻辑回归的可解释性\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E逻辑回归最大的特点就是\u003Cb\u003E可解释性\u003C\u002Fb\u003E很强。\u003C\u002Fp\u003E\u003Cp\u003E在模型训练完成之后，我们获得了一组n维的权重向量 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D\" alt=\"\\bm{w}\" eeimg=\"1\"\u002F\u003E 跟偏差 b。\u003C\u002Fp\u003E\u003Cp\u003E对于权重向量 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D\" alt=\"\\bm{w}\" eeimg=\"1\"\u002F\u003E，它的每一个维度的值，代表了这个维度的特征对于最终分类结果的贡献大小。假如这个维度是正，说明这个特征对于结果是有正向的贡献，那么它的值越大，说明这个特征对于分类为正起到的作用越重要。\u003C\u002Fp\u003E\u003Cp\u003E对于偏差b (Bias)，一定程度代表了正负两个类别的判定的容易程度。假如b是0，那么正负类别是均匀的。如果b大于0，说明它更容易被分为正类，反之亦然。\u003C\u002Fp\u003E\u003Cp\u003E根据逻辑回归里的权重向量在每个特征上面的大小，就能够对于每个特征的重要程度有一个量化的清楚的认识，这就是为什么说逻辑回归模型有着很强的解释性的原因。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E十、决策边界\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E补充评论里的一个问题，逻辑回归的决策边界是否是线性的，相当于问曲线：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cfrac%7B1%7D%7B1%2Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%7D%7D+%3D+0.5\" alt=\"\\frac{1}{1+e^{-\\bm{w}^T\\bm{x}}} = 0.5\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E是不是的线性的，我们可以稍微化简一下上面的曲线公式，得到：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=e%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%7D+%3D+1+%3D+e%5E%7B0%7D+%5C%5C+%E5%8D%B3++-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D+%3D+0\" alt=\"e^{-\\bm{w}^T\\bm{x}} = 1 = e^{0} \\\\ 即  -\\bm{w}^T\\bm{x} = 0\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E我们得到了一个等价的曲线，显然它是一个超平面（它在数据是二维的情况下是一条直线）。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-3f2227d606b29be9619566b88d1f1912_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1934\" data-rawheight=\"1098\" class=\"origin_image zh-lightbox-thumb\" width=\"1934\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-3f2227d606b29be9619566b88d1f1912_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1934&#39; height=&#39;1098&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1934\" data-rawheight=\"1098\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1934\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-3f2227d606b29be9619566b88d1f1912_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-3f2227d606b29be9619566b88d1f1912_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cb\u003E十一、总结\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E终于一切都搞清楚了，现在我们来理一理思路，首先逻辑回归模型长这样：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=y%3D%5Cfrac%7B1%7D%7B1%2Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D%7D%7D\" alt=\"y=\\frac{1}{1+e^{-\\bm{w}^T\\bm{x}}}\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E其中我们不知道的量是 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D\" alt=\"\\bm{w}\" eeimg=\"1\"\u002F\u003E ，假设我们已经训练好了一个 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D%5E%2A\" alt=\"\\bm{w}^*\" eeimg=\"1\"\u002F\u003E , 我们用模型来判断 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bx%7D_i\" alt=\"\\bm{x}_i\" eeimg=\"1\"\u002F\u003E 的标签呢？很简单，直接将\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bx%7D_i\" alt=\"\\bm{x}_i\" eeimg=\"1\"\u002F\u003E代入y中，求出来的值就是\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bx%7D_i\" alt=\"\\bm{x}_i\" eeimg=\"1\"\u002F\u003E的标签是1的概率，如果概率大于0.5，那么我们认为它就是1类，否则就是0类。\u003C\u002Fp\u003E\u003Cp\u003E那怎么得到 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D%5E%2A\" alt=\"\\bm{w}^*\" eeimg=\"1\"\u002F\u003E 呢？\u003C\u002Fp\u003E\u003Cp\u003E如果采用随机梯度下降法的话，我们首先随机产生一个\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D\" alt=\"\\bm{w}\" eeimg=\"1\"\u002F\u003E的初始值 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D_0\" alt=\"\\bm{w}_0\" eeimg=\"1\"\u002F\u003E ,然后通过公式不断迭代从而求得\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D%5E%2A\" alt=\"\\bm{w}^*\" eeimg=\"1\"\u002F\u003E的值：\u003C\u002Fp\u003E\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%5Cbm%7Bw%7D_%7Bt%2B1%7D+%3D+%5Cbm%7Bw%7D_t+%2B+%5Ceta+++%7B%28y_n-+%5Cfrac%7B1%7D%7B1%2Be%5E%7B-%5Cbm%7Bw%7D%5ET%5Cbm%7Bx%7D_n%7D%7D+%29%5Cbm%7Bx%7D_n%7D\" alt=\"\\bm{w}_{t+1} = \\bm{w}_t + \\eta   {(y_n- \\frac{1}{1+e^{-\\bm{w}^T\\bm{x}_n}} )\\bm{x}_n}\" eeimg=\"1\"\u002F\u003E \u003C\u002Fp\u003E\u003Cp\u003E每次迭代都从所有样本中随机抽取一个 \u003Cimg src=\"https:\u002F\u002Fwww.zhihu.com\u002Fequation?tex=%28%5Cbm%7Bx_i%7D%2Cy_i%29\" alt=\"(\\bm{x_i},y_i)\" eeimg=\"1\"\u002F\u003E 来代入上述方程。\u003C\u002Fp\u003E\u003Chr\u002F\u003E\u003Cp\u003E原创，转载请注明出处。\u003C\u002Fp\u003E\u003Cp\u003E初学者，不可避免出现错误。如果有任何问题，欢迎大家指正，也欢迎大家一起来交流讨论。\u003C\u002Fp\u003E","adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F19559450","type":"topic","id":"19559450","name":"机器学习"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F20178024","type":"topic","id":"20178024","name":"逻辑回归"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F19650497","type":"topic","id":"19650497","name":"梯度下降"}],"voteupCount":291,"voting":0,"column":{"description":"公众号[自然语言处理与机器学习] 微信号yizhennotes","canManage":false,"intro":"公号[机器学习算法与自然语言处理] 微信号yizhennotes","isFollowing":true,"urlToken":"qinlibo-ml","id":"qinlibo-ml","articlesCount":314,"acceptSubmission":true,"title":"机器学习算法与自然语言处理","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fqinlibo-ml","commentPermission":"all","created":1484138601,"updated":1500729447,"imageUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-dade4f3465c87462e77ba24a253c0e20_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f575fa4bf1afd510f4d61486358122bd_{size}.jpg","uid":"38273409875968","userType":"people","isFollowing":false,"urlToken":"qinlibo_nlp","id":"1b72d70b702b3920638f0235d380ebd8","description":"个人微信：qinlibo20133868.【添加注明来自知乎和备注】\n个人公众号[机器学习算法与自然语言处理][yizhennotes]\n本科当过学生教员，善于讲课~\n现在在工大做自然语言处理\n我已委托“维权骑士”（http:\u002F\u002Frightknights.com）为我的文章进行维权行动","name":"忆臻","isAdvertiser":false,"headline":"PHD Candidate（公众号机器学习算法与自然语言处理）","gender":1,"url":"\u002Fpeople\u002F1b72d70b702b3920638f0235d380ebd8","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f575fa4bf1afd510f4d61486358122bd_l.jpg","isOrg":false,"type":"people"},"followers":27633,"type":"column"},"commentCount":47,"contributions":[{"id":2102478,"state":"accepted","type":"include","column":{"description":"公众号[自然语言处理与机器学习] 微信号yizhennotes","canManage":false,"intro":"公号[机器学习算法与自然语言处理] 微信号yizhennotes","isFollowing":true,"urlToken":"qinlibo-ml","id":"qinlibo-ml","articlesCount":314,"acceptSubmission":true,"title":"机器学习算法与自然语言处理","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fqinlibo-ml","commentPermission":"all","created":1484138601,"updated":1500729447,"imageUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-dade4f3465c87462e77ba24a253c0e20_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f575fa4bf1afd510f4d61486358122bd_{size}.jpg","uid":"38273409875968","userType":"people","isFollowing":false,"urlToken":"qinlibo_nlp","id":"1b72d70b702b3920638f0235d380ebd8","description":"个人微信：qinlibo20133868.【添加注明来自知乎和备注】\n个人公众号[机器学习算法与自然语言处理][yizhennotes]\n本科当过学生教员，善于讲课~\n现在在工大做自然语言处理\n我已委托“维权骑士”（http:\u002F\u002Frightknights.com）为我的文章进行维权行动","name":"忆臻","isAdvertiser":false,"headline":"PHD Candidate（公众号机器学习算法与自然语言处理）","gender":1,"url":"\u002Fpeople\u002F1b72d70b702b3920638f0235d380ebd8","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f575fa4bf1afd510f4d61486358122bd_l.jpg","isOrg":false,"type":"people"},"followers":27633,"type":"column"}},{"id":2102479,"state":"accepted","type":"include","column":{"description":"这是一个初学者的专栏，我们和初学者一起入门机器学习。在这里，我们不采用快速推进的模式。从最基本的数学基础到最前沿的应用，一步一个脚印，让扎实的读者拥有成为机器学习专家的潜力。","canManage":false,"intro":"和读者一起征服机器学习的星辰大海","isFollowing":true,"urlToken":"MLstudy","id":"MLstudy","articlesCount":55,"acceptSubmission":true,"title":"从零开始:一起入门机器学习","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002FMLstudy","commentPermission":"all","created":1530067258,"updated":1530114620,"imageUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-a64760163f85c6deb6dc46852d82d8f0_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-c53e6c4168770bfe4ff1581e9bab625f_{size}.jpg","uid":"71772808413184","userType":"people","isFollowing":false,"urlToken":"96-48","id":"5004ad407abca0f38da16504192f77e5","description":"自律给我自由","name":"The one","isAdvertiser":false,"headline":"博客：chrer.com\n私信咨询请走值乎","gender":1,"url":"\u002Fpeople\u002F5004ad407abca0f38da16504192f77e5","avatarUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-c53e6c4168770bfe4ff1581e9bab625f_l.jpg","isOrg":false,"type":"people"},"followers":854,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":false,"tipjarorsCount":0,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"isNormal":true,"status":0,"shareText":"逻辑回归 logistics regression 公式推导 - 来自知乎专栏「机器学习算法与自然语言处理」，作者: 折射 https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F44591359 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""}}},"columns":{"qinlibo-ml":{"description":"公众号[自然语言处理与机器学习] 微信号yizhennotes","canManage":false,"intro":"公号[机器学习算法与自然语言处理] 微信号yizhennotes","isFollowing":true,"urlToken":"qinlibo-ml","id":"qinlibo-ml","articlesCount":314,"acceptSubmission":true,"title":"机器学习算法与自然语言处理","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fqinlibo-ml","commentPermission":"all","created":1484138601,"updated":1500729447,"imageUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-dade4f3465c87462e77ba24a253c0e20_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f575fa4bf1afd510f4d61486358122bd_{size}.jpg","uid":"38273409875968","userType":"people","isFollowing":false,"urlToken":"qinlibo_nlp","id":"1b72d70b702b3920638f0235d380ebd8","description":"个人微信：qinlibo20133868.【添加注明来自知乎和备注】\n个人公众号[机器学习算法与自然语言处理][yizhennotes]\n本科当过学生教员，善于讲课~\n现在在工大做自然语言处理\n我已委托“维权骑士”（http:\u002F\u002Frightknights.com）为我的文章进行维权行动","name":"忆臻","isAdvertiser":false,"headline":"PHD Candidate（公众号机器学习算法与自然语言处理）","gender":1,"url":"\u002Fpeople\u002F1b72d70b702b3920638f0235d380ebd8","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-f575fa4bf1afd510f4d61486358122bd_l.jpg","isOrg":false,"type":"people"},"followers":27633,"type":"column"},"MLstudy":{"description":"这是一个初学者的专栏，我们和初学者一起入门机器学习。在这里，我们不采用快速推进的模式。从最基本的数学基础到最前沿的应用，一步一个脚印，让扎实的读者拥有成为机器学习专家的潜力。","canManage":false,"intro":"和读者一起征服机器学习的星辰大海","isFollowing":true,"urlToken":"MLstudy","id":"MLstudy","articlesCount":55,"acceptSubmission":true,"title":"从零开始:一起入门机器学习","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002FMLstudy","commentPermission":"all","created":1530067258,"updated":1530114620,"imageUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-a64760163f85c6deb6dc46852d82d8f0_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-c53e6c4168770bfe4ff1581e9bab625f_{size}.jpg","uid":"71772808413184","userType":"people","isFollowing":false,"urlToken":"96-48","id":"5004ad407abca0f38da16504192f77e5","description":"自律给我自由","name":"The one","isAdvertiser":false,"headline":"博客：chrer.com\n私信咨询请走值乎","gender":1,"url":"\u002Fpeople\u002F5004ad407abca0f38da16504192f77e5","avatarUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-c53e6c4168770bfe4ff1581e9bab625f_l.jpg","isOrg":false,"type":"people"},"followers":854,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{},"posts":{},"clubs":{}},"currentUser":"0f4e368fc584d10034f416ab5f93a4c0","account":{"lockLevel":{},"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false}},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{}},"env":{"ab":{"config":{"experiments":[{"expId":"launch-gw_sem_temp-2","expPrefix":"gw_sem_temp","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-gw_ydyq-2","expPrefix":"gw_ydyq","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-li_price_test-5","expPrefix":"li_price_test","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-nw_zhuantigaiban-2","expPrefix":"nw_zhuantigaiban","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-nw_zhuantikapian-7","expPrefix":"nw_zhuantikapian","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-qa_answer_update-2","expPrefix":"qa_answer_update","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-se_collegecm-3","expPrefix":"se_collegecm","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-se_d2q-3","expPrefix":"se_d2q","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-se_ios_spb309-5","expPrefix":"se_ios_spb309","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-se_ir-2","expPrefix":"se_ir","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-se_payconsult-3","expPrefix":"se_payconsult","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-se_subtext-2","expPrefix":"se_subtext","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-se_wannasearch-5","expPrefix":"se_wannasearch","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-se_webtimebox-2","expPrefix":"se_webtimebox","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-se_whitelist-2","expPrefix":"se_whitelist","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-top_hotchild-2","expPrefix":"top_hotchild","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-tp_and_sticky-2","expPrefix":"tp_and_sticky","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-us_bigone-10","expPrefix":"us_bigone","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-us_foltopic_user-10","expPrefix":"us_foltopic_user","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-us_newguide3-11","expPrefix":"us_newguide3","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-us_n_web_msg-5","expPrefix":"us_n_web_msg","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_videoad-3","expPrefix":"vd_videoad","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"li_qa_new_cover-2","expPrefix":"li_qa_new_cover","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"se_likebutton-2","expPrefix":"se_likebutton","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"se_mclick-7","expPrefix":"se_mclick","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"us_bignew-1","expPrefix":"us_bignew","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"us_update-8","expPrefix":"us_update","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"us_notification-2","expPrefix":"us_notification","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"top_native_ans-5","expPrefix":"top_native_ans","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"top_recall_expr-6","expPrefix":"top_recall_expr","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"top_vipconsume-6","expPrefix":"top_vipconsume","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"top_gr_ab_exp-7","expPrefix":"top_gr_ab_exp","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"top_recall_v2-3","expPrefix":"top_recall_v2","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"top_hotctr-8","expPrefix":"top_hotctr","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false}],"params":[{"id":"web_heifetz_grow_ad","type":"String","value":"1"},{"id":"se_billboardsearch","type":"String","value":"0","chainId":"_all_"},{"id":"se_college_cm","type":"String","value":"1","chainId":"_all_"},{"id":"li_album_liutongab","type":"String","value":"0","chainId":"_all_"},{"id":"web_wx_block","type":"String","value":"2"},{"id":"zr_intervene","type":"String","value":"0","chainId":"_all_"},{"id":"zr_rec_answer_cp","type":"String","value":"close","chainId":"_all_"},{"id":"top_new_feed","type":"String","value":"5","chainId":"_all_"},{"id":"li_android_vip","type":"String","value":"0","chainId":"_all_"},{"id":"li_qa_new_cover","type":"String","value":"1","chainId":"_all_"},{"id":"zr_answer_rec_cp","type":"String","value":"open","chainId":"_all_"},{"id":"top_root","type":"String","value":"0","chainId":"_all_"},{"id":"top_rank","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_kv","type":"String","value":"0","chainId":"_all_"},{"id":"se_wannasearch","type":"String","value":"a","chainId":"_all_"},{"id":"se_featured","type":"String","value":"1","chainId":"_all_"},{"id":"soc_update","type":"String","value":"0","chainId":"_all_"},{"id":"pf_fuceng","type":"String","value":"1","chainId":"_all_"},{"id":"se_ltr_ck","type":"String","value":"0","chainId":"_all_"},{"id":"se_ltr_gc","type":"String","value":"0","chainId":"_all_"},{"id":"se_p_slideshow","type":"String","value":"0","chainId":"_all_"},{"id":"se_webrs","type":"String","value":"1","chainId":"_all_"},{"id":"se_d2q","type":"String","value":"1","chainId":"_all_"},{"id":"top_native_answer","type":"String","value":"3","chainId":"_all_"},{"id":"ug_newtag","type":"String","value":"1","chainId":"_all_"},{"id":"ls_videoad","type":"String","value":"2","chainId":"_all_"},{"id":"li_search_answer","type":"String","value":"0","chainId":"_all_"},{"id":"se_expired_ob","type":"String","value":"0","chainId":"_all_"},{"id":"se_ri","type":"String","value":"0","chainId":"_all_"},{"id":"ug_goodcomment_0","type":"String","value":"1","chainId":"_all_"},{"id":"zr_article_rec_rank","type":"String","value":"close","chainId":"_all_"},{"id":"top_recall_deep_user","type":"String","value":"1","chainId":"_all_"},{"id":"tsp_vote","type":"String","value":"1","chainId":"_all_"},{"id":"tsp_hotctr","type":"String","value":"1","chainId":"_all_"},{"id":"pf_creator_card","type":"String","value":"1","chainId":"_all_"},{"id":"zr_infinity_a_u","type":"String","value":"all","chainId":"_all_"},{"id":"se_zu_recommend","type":"String","value":"0","chainId":"_all_"},{"id":"se_agency","type":"String","value":" 0","chainId":"_all_"},{"id":"pf_newguide_vertical","type":"String","value":"0","chainId":"_all_"},{"id":"tp_header_style","type":"String","value":"1","chainId":"_all_"},{"id":"soc_special","type":"String","value":"0","chainId":"_all_"},{"id":"li_tjys_ec_ab","type":"String","value":"0","chainId":"_all_"},{"id":"se_webmajorob","type":"String","value":"0","chainId":"_all_"},{"id":"se_famous","type":"String","value":"1","chainId":"_all_"},{"id":"se_movietab","type":"String","value":"1","chainId":"_all_"},{"id":"se_new_topic","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sticky_android","type":"String","value":"2","chainId":"_all_"},{"id":"tsp_newchild","type":"String","value":"1","chainId":"_all_"},{"id":"ug_follow_answerer_0","type":"String","value":"0","chainId":"_all_"},{"id":"zr_km_slot_style","type":"String","value":"event_card","chainId":"_all_"},{"id":"zr_slot_cold_start","type":"String","value":"default","chainId":"_all_"},{"id":"se_topiclabel","type":"String","value":"1","chainId":"_all_"},{"id":"zr_video_rank","type":"String","value":"new_rank","chainId":"_all_"},{"id":"top_test_4_liguangyi","type":"String","value":"1","chainId":"_all_"},{"id":"zr_search_xgb","type":"String","value":"0","chainId":"_all_"},{"id":"se_ltr_nn","type":"String","value":"0","chainId":"_all_"},{"id":"se_lottery","type":"String","value":"0","chainId":"_all_"},{"id":"se_webtimebox","type":"String","value":"1","chainId":"_all_"},{"id":"se_zu_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_subtext","type":"String","value":"1","chainId":"_all_"},{"id":"li_se_xgb","type":"String","value":"0","chainId":"_all_"},{"id":"qa_answerlist_ad","type":"String","value":"0","chainId":"_all_"},{"id":"zr_video_rank_nn","type":"String","value":"new_rank","chainId":"_all_"},{"id":"se_preset_tech","type":"String","value":"0","chainId":"_all_"},{"id":"se_site_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"top_v_album","type":"String","value":"1","chainId":"_all_"},{"id":"li_pay_banner_type","type":"String","value":"0","chainId":"_all_"},{"id":"qa_test","type":"String","value":"0","chainId":"_all_"},{"id":"zr_infinity_small","type":"String","value":"256","chainId":"_all_"},{"id":"top_hotcommerce","type":"String","value":"1","chainId":"_all_"},{"id":"pf_noti_entry_num","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_paid_answer","type":"String","value":"0","chainId":"_all_"},{"id":"se_topicdirect","type":"String","value":"2","chainId":"_all_"},{"id":"top_universalebook","type":"String","value":"1","chainId":"_all_"},{"id":"se_websearch","type":"String","value":"3","chainId":"_all_"},{"id":"web_n_web_msg","type":"String","value":"1"},{"id":"li_price_test","type":"String","value":"1","chainId":"_all_"},{"id":"web_answer_list_ad","type":"String","value":"1"},{"id":"se_ad_index","type":"String","value":"10","chainId":"_all_"},{"id":"se_mobileweb","type":"String","value":"1","chainId":"_all_"},{"id":"top_gr_ab","type":"String","value":"7","chainId":"_all_"},{"id":"ug_follow_topic_1","type":"String","value":"2","chainId":"_all_"},{"id":"gue_new_special_page","type":"String","value":"1"},{"id":"zr_video_recall","type":"String","value":"current_recall","chainId":"_all_"},{"id":"zr_km_style","type":"String","value":"base","chainId":"_all_"},{"id":"zr_ans_rec","type":"String","value":"gbrank","chainId":"_all_"},{"id":"zr_km_tag","type":"String","value":"open","chainId":"_all_"},{"id":"tp_qa_toast","type":"String","value":"1","chainId":"_all_"},{"id":"tp_meta_card","type":"String","value":"0","chainId":"_all_"},{"id":"tp_qa_metacard","type":"String","value":"1","chainId":"_all_"},{"id":"top_quality","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sft","type":"String","value":"a","chainId":"_all_"},{"id":"top_vipconsume","type":"String","value":"1","chainId":"_all_"},{"id":"soc_bigone","type":"String","value":"1","chainId":"_all_"},{"id":"pf_foltopic_usernum","type":"String","value":"50","chainId":"_all_"},{"id":"web_answer_update","type":"String","value":"1"},{"id":"zr_rel_search","type":"String","value":"base","chainId":"_all_"},{"id":"se_payconsult","type":"String","value":"5","chainId":"_all_"},{"id":"tsp_lastread","type":"String","value":"0","chainId":"_all_"},{"id":"li_se_album_card","type":"String","value":"0","chainId":"_all_"},{"id":"li_ts_sample","type":"String","value":"old","chainId":"_all_"},{"id":"se_ios_spb309","type":"String","value":"1","chainId":"_all_"},{"id":"tsp_childbillboard","type":"String","value":"2","chainId":"_all_"},{"id":"ls_new_upload","type":"String","value":"0","chainId":"_all_"},{"id":"se_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"se_search_feed","type":"String","value":"N","chainId":"_all_"},{"id":"se_backsearch","type":"String","value":"0","chainId":"_all_"},{"id":"se_colorfultab","type":"String","value":"1","chainId":"_all_"},{"id":"se_waterfall","type":"String","value":"0","chainId":"_all_"},{"id":"ls_fmp4","type":"String","value":"0","chainId":"_all_"},{"id":"se_go_ztext","type":"String","value":"0","chainId":"_all_"},{"id":"se_likebutton","type":"String","value":"1","chainId":"_all_"},{"id":"se_mclick","type":"String","value":"0","chainId":"_all_"},{"id":"se_rr","type":"String","value":"1","chainId":"_all_"},{"id":"tp_qa_metacard_top","type":"String","value":"top","chainId":"_all_"},{"id":"web_answerlist_ad","type":"String","value":"0"},{"id":"se_auto_syn","type":"String","value":"0","chainId":"_all_"},{"id":"tp_m_intro_re_topic","type":"String","value":"1","chainId":"_all_"},{"id":"se_mclick1","type":"String","value":"2","chainId":"_all_"},{"id":"se_amovietab","type":"String","value":"1","chainId":"_all_"},{"id":"top_recall_exp_v1","type":"String","value":"6","chainId":"_all_"},{"id":"ug_zero_follow_0","type":"String","value":"0","chainId":"_all_"},{"id":"ug_fw_answ_aut_1","type":"String","value":"0","chainId":"_all_"},{"id":"web_sem_ab","type":"String","value":"1"},{"id":"web_column_auto_invite","type":"String","value":"0"},{"id":"zr_km_xgb_model","type":"String","value":"new_xgb","chainId":"_all_"},{"id":"top_ebook","type":"String","value":"0","chainId":"_all_"},{"id":"top_recall_exp_v2","type":"String","value":"3","chainId":"_all_"},{"id":"ug_zero_follow","type":"String","value":"0","chainId":"_all_"},{"id":"se_whitelist","type":"String","value":"1","chainId":"_all_"},{"id":"se_time_threshold","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sft_v2","type":"String","value":"d","chainId":"_all_"},{"id":"soc_bignew","type":"String","value":"1","chainId":"_all_"},{"id":"soc_notification","type":"String","value":"1","chainId":"_all_"},{"id":"li_hot_score_ab","type":"String","value":"0","chainId":"_all_"},{"id":"zr_art_rec","type":"String","value":"base","chainId":"_all_"},{"id":"se_limit","type":"String","value":"0","chainId":"_all_"},{"id":"se_college","type":"String","value":"default","chainId":"_all_"},{"id":"li_back","type":"String","value":"0","chainId":"_all_"},{"id":"li_ebook_detail","type":"String","value":"1","chainId":"_all_"},{"id":"web_question_invite","type":"String","value":"B"},{"id":"zr_km_answer","type":"String","value":"open_cvr","chainId":"_all_"},{"id":"zr_km_paid_answer","type":"String","value":"0","chainId":"_all_"},{"id":"tp_topic_head","type":"String","value":"1","chainId":"_all_"},{"id":"gue_anonymous","type":"String","value":"show"},{"id":"top_ydyq","type":"String","value":"A","chainId":"_all_"},{"id":"li_qa_cover","type":"String","value":"old","chainId":"_all_"},{"id":"gue_zhuantikapian","type":"String","value":"5"},{"id":"ug_follow_answerer","type":"String","value":"0","chainId":"_all_"}],"chains":[{"chainId":"_all_"}]},"triggers":{}},"userAgent":{"Edge":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":false,"Android":false,"iOS":false,"isAppleDevice":true,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"isWebView":false,"origin":"Mozilla\u002F5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit\u002F537.36 (KHTML, like Gecko) Chrome\u002F75.0.3770.142 Safari\u002F537.36"},"ctx":{"path":"\u002Fp\u002F44591359"},"trafficSource":"production","edition":{"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false},"theme":"light","enableShortcut":true,"referer":"https:\u002F\u002Fgithub.com\u002Fmarkliu2013\u002Fmachine-learning","conf":{},"ipInfo":{"cityName":"Fremont","countryName":"United States","regionName":"California","countryCode":"US"},"logged":true,"tdkInfo":{}},"me":{"columnContributions":[]},"label":{"recognizerLists":{}},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"active":{"sendDigitsError":null,"activeConfirmSucceeded":null,"activeConfirmError":null},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false,"captchaBase64String":null,"captchaValidationMessage":null,"loginCaptchaExpires":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"creator":{"currentCreatorUrlToken":null,"homeData":{"recommendQuestions":[]},"tools":{"question":{"invitationCount":{"questionFolloweeCount":0,"questionTotalCount":0},"goodatTopics":[]},"customPromotion":{"itemLists":{}},"recommend":{"recommendTimes":{}}},"explore":{"academy":{"tabs":[],"article":{}}},"rights":[],"rightsStatus":{},"levelUpperLimit":10,"account":{"growthLevel":{}},"applyStatus":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotListCategories":[],"hotList":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"qinlibo-ml","MLstudy"]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[],"contributionInvitation":null},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]}},"fetchHost":"www.zhihu.com","subAppName":"column"}</script><script src="./逻辑回归 logistics regression 公式推导 - 知乎_files/vendor.7842b402f56b92d57f3e.js"></script><script src="./逻辑回归 logistics regression 公式推导 - 知乎_files/column.app.459e827e712d244b6a60.js"></script><script></script><div><div style="display: none;">想来知乎工作？请发送邮件到 jobs@zhihu.com</div></div><script src="./逻辑回归 logistics regression 公式推导 - 知乎_files/zap.js"></script><div><div><div class="Editable-languageSuggestions" style="left: -1179px; top: -999px;"><div><div class="Popover"><div class="Editable-languageSuggestionsInput Input-wrapper"><input autocomplete="off" role="combobox" aria-expanded="false" aria-autocomplete="list" aria-activedescendant="AutoComplete77-0" id="Popover76-toggle" aria-haspopup="true" aria-owns="Popover76-content" class="Input" placeholder="选择语言" value=""><div class="Input-after"><svg class="Zi Zi--Select" fill="#afbdcf" viewBox="0 0 24 24" width="24" height="24"><path d="M12 16.183l2.716-2.966a.757.757 0 0 1 1.064.001.738.738 0 0 1 0 1.052l-3.247 3.512a.758.758 0 0 1-1.064 0L8.22 14.27a.738.738 0 0 1 0-1.052.758.758 0 0 1 1.063 0L12 16.183zm0-9.365L9.284 9.782a.758.758 0 0 1-1.064 0 .738.738 0 0 1 0-1.052l3.248-3.512a.758.758 0 0 1 1.065 0L15.78 8.73a.738.738 0 0 1 0 1.052.757.757 0 0 1-1.063.001L12 6.818z" fill-rule="evenodd"></path></svg></div></div></div></div></div></div></div><div><div><div></div></div></div></body></html>